<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>从零实现高性能 CPU 矩阵乘法：逼近 OpenBLAS 的优化之路</title>
    <link href="/hpc/cpu/matmul.html"/>
    <url>/hpc/cpu/matmul.html</url>
    
    <content type="html"><![CDATA[<p>在大模型推理引擎开发中，矩阵乘法（GEMM）是最核心的计算密集型算子。虽然可以直接调用 OpenBLAS、MKL 等成熟库，但在实际工程中存在一些问题：</p><ol><li>库体积问题：OpenBLAS 占用数十 MB，影响推理引擎的部署体积</li><li>线程池冲突：OpenBLAS 内部维护线程池，与 OpenMP 混用时会产生资源竞争</li><li>学习价值：手写 GEMM 是理解计算机体系结构的绝佳实践</li></ol><p>本文记录了我从零实现一个高性能 CPU 矩阵乘法的完整过程，最终在单核条件下达到 OpenBLAS <strong>82%</strong> 的性能，而在 24 核并行时超越 <strong>OpenBLAS 6%</strong>。具体的性能测试结果参见：<a href="https://github.com/tianyuxbear/matmul-cpu">https://github.com/tianyuxbear/matmul-cpu</a></p><p><strong>问题定义：</strong></p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="55.433ex" height="2.466ex" role="img" focusable="false" viewBox="0 -896 24501.3 1090" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path><path id="MJX-1-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-1-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path><path id="MJX-1-TEX-I-1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path id="MJX-1-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-1-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-1-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-1-TEX-N-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path id="MJX-1-TEX-D-211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path><path id="MJX-1-TEX-I-1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path><path id="MJX-1-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path id="MJX-1-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path><path id="MJX-1-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(1037.8,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(2093.6,0)"><use data-c="1D434" xlink:href="#MJX-1-TEX-I-1D434"></use></g><g data-mml-node="msup" transform="translate(2843.6,0)"><g data-mml-node="mi"><use data-c="1D435" xlink:href="#MJX-1-TEX-I-1D435"></use></g><g data-mml-node="mi" transform="translate(792,413) scale(0.707)"><use data-c="1D447" xlink:href="#MJX-1-TEX-I-1D447"></use></g></g><g data-mml-node="mo" transform="translate(4405.6,0)"><use data-c="2B" xlink:href="#MJX-1-TEX-N-2B"></use></g><g data-mml-node="mi" transform="translate(5405.8,0)"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(6165.8,0)"><use data-c="2C" xlink:href="#MJX-1-TEX-N-2C"></use></g><g data-mml-node="mstyle" transform="translate(6443.8,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(7610.5,0)"><use data-c="1D434" xlink:href="#MJX-1-TEX-I-1D434"></use></g><g data-mml-node="mo" transform="translate(8638.2,0)"><use data-c="2208" xlink:href="#MJX-1-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(9583,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-1-TEX-D-211D"></use></g></g><g data-mml-node="TeXAtom" transform="translate(755,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D440" xlink:href="#MJX-1-TEX-I-1D440"></use></g><g data-mml-node="mo" transform="translate(1051,0)"><use data-c="D7" xlink:href="#MJX-1-TEX-N-D7"></use></g><g data-mml-node="mi" transform="translate(1829,0)"><use data-c="1D43E" xlink:href="#MJX-1-TEX-I-1D43E"></use></g></g></g><g data-mml-node="mo" transform="translate(12309.9,0)"><use data-c="2C" xlink:href="#MJX-1-TEX-N-2C"></use></g><g data-mml-node="mstyle" transform="translate(12587.9,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(13754.6,0)"><use data-c="1D435" xlink:href="#MJX-1-TEX-I-1D435"></use></g><g data-mml-node="mo" transform="translate(14791.4,0)"><use data-c="2208" xlink:href="#MJX-1-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(15736.2,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-1-TEX-D-211D"></use></g></g><g data-mml-node="TeXAtom" transform="translate(755,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D441" xlink:href="#MJX-1-TEX-I-1D441"></use></g><g data-mml-node="mo" transform="translate(888,0)"><use data-c="D7" xlink:href="#MJX-1-TEX-N-D7"></use></g><g data-mml-node="mi" transform="translate(1666,0)"><use data-c="1D43E" xlink:href="#MJX-1-TEX-I-1D43E"></use></g></g></g><g data-mml-node="mo" transform="translate(18347.8,0)"><use data-c="2C" xlink:href="#MJX-1-TEX-N-2C"></use></g><g data-mml-node="mstyle" transform="translate(18625.8,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(19792.5,0)"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(20830.3,0)"><use data-c="2208" xlink:href="#MJX-1-TEX-N-2208"></use></g><g data-mml-node="msup" transform="translate(21775,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="211D" xlink:href="#MJX-1-TEX-D-211D"></use></g></g><g data-mml-node="TeXAtom" transform="translate(755,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D440" xlink:href="#MJX-1-TEX-I-1D440"></use></g><g data-mml-node="mo" transform="translate(1051,0)"><use data-c="D7" xlink:href="#MJX-1-TEX-N-D7"></use></g><g data-mml-node="mi" transform="translate(1829,0)"><use data-c="1D441" xlink:href="#MJX-1-TEX-I-1D441"></use></g></g></g></g></g></svg></mjx-container><p>所有矩阵均为 <strong>行主序(Row-Major)</strong> 存储。</p><p><strong>测试环境：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">CPU:             Intel Xeon Silver 4310 @ 2.10GHz (Turbo: 3.30GHz)<br>Sockets:         2<br>Cores/Socket:    12<br>Physical Cores:  24<br><br>Cache (per core):<br>  L1d:           48 KiB<br>  L2:            1.25 MiB<br>  L3:            18 MiB (shared)<br><br>ISA Extensions:  AVX, AVX2, AVX-512 (F/DQ/BW/VL/VNNI/VBMI/VBMI2)<br></code></pre></td></tr></table></figure><p><strong>理论峰值性能<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://www.intel.com/content/www/us/en/products/sku/215277/intel-xeon-silver-4310-processor-18m-cache-2-10-ghz/specifications.html">[1]</span></a></sup>：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">单精度峰值 FLOPS = 频率 × FMA端口数 × 每FMA操作数 × SIMD宽度<br>                = 2.2 GHz × 2 × 2 × 16<br>                = 140.8 GFLOPS/core (基频)<br>                = 211.2 GFLOPS/core (睿频)<br></code></pre></td></tr></table></figure><p><strong>理论峰值内存带宽<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="https://www.intel.com/content/www/us/en/products/sku/215277/intel-xeon-silver-4310-processor-18m-cache-2-10-ghz/specifications.html">[1]</span></a></sup>：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">理论峰值内存带宽：<br>= 内存传输速率 × 内存通道数 × 每通道数据宽度<br>= 2667 MT/s × 8 × 8 Byte<br>≈ 170.7 GB/s（单 Socket, 12核共享）<br>≈ 341.4 GB/s（双 Socket）<br></code></pre></td></tr></table></figure><p><strong>最终性能：</strong></p><div class="note note-info">            <p>矩阵规模 M &#x3D; N &#x3D; K &#x3D; 4096，2 次预热（warmup）轮次，10 次正式基准测试（benchmark）轮次。</p>           </div><table><thead><tr><th>配置</th><th>实现</th><th>Peak GFLOPS</th><th>Avg GFLOPS</th><th>vs OpenBLAS</th></tr></thead><tbody><tr><td>单核</td><td>本文实现</td><td>110.74</td><td>109.37</td><td>82.4%</td></tr><tr><td>单核</td><td>OpenBLAS</td><td>132.88</td><td>132.62</td><td>—</td></tr><tr><td>24核</td><td>本文实现</td><td>2010.61</td><td>1909.40</td><td><strong>106%</strong></td></tr><tr><td>24核</td><td>OpenBLAS</td><td>1914.91</td><td>1796.69</td><td>—</td></tr></tbody></table><h1 id="第一部分：理论基础"><a href="#第一部分：理论基础" class="headerlink" title="第一部分：理论基础"></a>第一部分：理论基础</h1><h2 id="1-1-Roofline-模型：计算瓶颈-vs-访存瓶颈"><a href="#1-1-Roofline-模型：计算瓶颈-vs-访存瓶颈" class="headerlink" title="1.1 Roofline 模型：计算瓶颈 vs 访存瓶颈"></a>1.1 Roofline 模型：计算瓶颈 vs 访存瓶颈</h2><p><img src="https://cdn.jsdelivr.net/gh/tianyuxbear/images/blog/roofline.png" alt="roofline"></p><ul><li><strong>算力 π</strong>：也称为计算平台的<strong>性能上限</strong>，指的是一个计算平台倾尽全力每秒钟所能完成的浮点运算数。单位是 <code>FLOPS</code> 或 <code>FLOP/s</code><sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Roofline Model与深度学习模型的性能分析](https://zhuanlan.zhihu.com/p/34204282)">[2]</span></a></sup>。</li></ul><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="34.408ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 15208.6 727" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path><path id="MJX-1-TEX-N-3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path id="MJX-1-TEX-I-1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path><path id="MJX-1-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-1-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-1-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-N-A0" d=""></path><path id="MJX-1-TEX-I-1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path id="MJX-1-TEX-I-1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path id="MJX-1-TEX-I-1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z"></path><path id="MJX-1-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path id="MJX-1-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-1-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-1-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJX-1-TEX-I-1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJX-1-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-1-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D70B" xlink:href="#MJX-1-TEX-I-1D70B"></use></g><g data-mml-node="mo" transform="translate(847.8,0)"><use data-c="3A" xlink:href="#MJX-1-TEX-N-3A"></use></g><g data-mml-node="mi" transform="translate(1403.6,0)"><use data-c="1D440" xlink:href="#MJX-1-TEX-I-1D440"></use></g><g data-mml-node="mi" transform="translate(2454.6,0)"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(2983.6,0)"><use data-c="1D465" xlink:href="#MJX-1-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(3555.6,0)"><use data-c="1D456" xlink:href="#MJX-1-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(3900.6,0)"><use data-c="1D45A" xlink:href="#MJX-1-TEX-I-1D45A"></use></g><g data-mml-node="mi" transform="translate(4778.6,0)"><use data-c="1D462" xlink:href="#MJX-1-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(5350.6,0)"><use data-c="1D45A" xlink:href="#MJX-1-TEX-I-1D45A"></use></g><g data-mml-node="mtext" transform="translate(6228.6,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(6478.6,0)"><use data-c="1D439" xlink:href="#MJX-1-TEX-I-1D439"></use></g><g data-mml-node="mi" transform="translate(7227.6,0)"><use data-c="1D43F" xlink:href="#MJX-1-TEX-I-1D43F"></use></g><g data-mml-node="mi" transform="translate(7908.6,0)"><use data-c="1D442" xlink:href="#MJX-1-TEX-I-1D442"></use></g><g data-mml-node="mi" transform="translate(8671.6,0)"><use data-c="1D443" xlink:href="#MJX-1-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(9422.6,0)"><use data-c="1D460" xlink:href="#MJX-1-TEX-I-1D460"></use></g><g data-mml-node="mtext" transform="translate(9891.6,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(10141.6,0)"><use data-c="1D443" xlink:href="#MJX-1-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(10892.6,0)"><use data-c="1D452" xlink:href="#MJX-1-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(11358.6,0)"><use data-c="1D45F" xlink:href="#MJX-1-TEX-I-1D45F"></use></g><g data-mml-node="mtext" transform="translate(11809.6,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(12059.6,0)"><use data-c="1D446" xlink:href="#MJX-1-TEX-I-1D446"></use></g><g data-mml-node="mi" transform="translate(12704.6,0)"><use data-c="1D452" xlink:href="#MJX-1-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(13170.6,0)"><use data-c="1D450" xlink:href="#MJX-1-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(13603.6,0)"><use data-c="1D45C" xlink:href="#MJX-1-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(14088.6,0)"><use data-c="1D45B" xlink:href="#MJX-1-TEX-I-1D45B"></use></g><g data-mml-node="mi" transform="translate(14688.6,0)"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"></use></g></g></g></svg></mjx-container><ul><li><strong>带宽 β</strong>：也即计算平台的<strong>带宽上限</strong>，指的是一个计算平台倾尽全力每秒所能完成的内存交换量。单位是 <code>Byte/s</code><sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Roofline Model与深度学习模型的性能分析](https://zhuanlan.zhihu.com/p/34204282)">[2]</span></a></sup>。</li></ul><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="42.721ex" height="2.084ex" role="img" focusable="false" viewBox="0 -716 18882.6 921" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path><path id="MJX-1-TEX-N-3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path id="MJX-1-TEX-I-1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path><path id="MJX-1-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-1-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-1-TEX-I-1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-N-A0" d=""></path><path id="MJX-1-TEX-I-1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path id="MJX-1-TEX-I-1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path id="MJX-1-TEX-I-1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path><path id="MJX-1-TEX-I-1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path id="MJX-1-TEX-I-1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path id="MJX-1-TEX-I-1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path id="MJX-1-TEX-I-1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path id="MJX-1-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D6FD" xlink:href="#MJX-1-TEX-I-1D6FD"></use></g><g data-mml-node="mo" transform="translate(843.8,0)"><use data-c="3A" xlink:href="#MJX-1-TEX-N-3A"></use></g><g data-mml-node="mi" transform="translate(1399.6,0)"><use data-c="1D440" xlink:href="#MJX-1-TEX-I-1D440"></use></g><g data-mml-node="mi" transform="translate(2450.6,0)"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(2979.6,0)"><use data-c="1D465" xlink:href="#MJX-1-TEX-I-1D465"></use></g><g data-mml-node="mi" transform="translate(3551.6,0)"><use data-c="1D456" xlink:href="#MJX-1-TEX-I-1D456"></use></g><g data-mml-node="mi" transform="translate(3896.6,0)"><use data-c="1D45A" xlink:href="#MJX-1-TEX-I-1D45A"></use></g><g data-mml-node="mi" transform="translate(4774.6,0)"><use data-c="1D462" xlink:href="#MJX-1-TEX-I-1D462"></use></g><g data-mml-node="mi" transform="translate(5346.6,0)"><use data-c="1D45A" xlink:href="#MJX-1-TEX-I-1D45A"></use></g><g data-mml-node="mtext" transform="translate(6224.6,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(6474.6,0)"><use data-c="1D440" xlink:href="#MJX-1-TEX-I-1D440"></use></g><g data-mml-node="mi" transform="translate(7525.6,0)"><use data-c="1D452" xlink:href="#MJX-1-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(7991.6,0)"><use data-c="1D45A" xlink:href="#MJX-1-TEX-I-1D45A"></use></g><g data-mml-node="mi" transform="translate(8869.6,0)"><use data-c="1D45C" xlink:href="#MJX-1-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(9354.6,0)"><use data-c="1D45F" xlink:href="#MJX-1-TEX-I-1D45F"></use></g><g data-mml-node="mi" transform="translate(9805.6,0)"><use data-c="1D466" xlink:href="#MJX-1-TEX-I-1D466"></use></g><g data-mml-node="mtext" transform="translate(10295.6,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(10545.6,0)"><use data-c="1D434" xlink:href="#MJX-1-TEX-I-1D434"></use></g><g data-mml-node="mi" transform="translate(11295.6,0)"><use data-c="1D450" xlink:href="#MJX-1-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(11728.6,0)"><use data-c="1D450" xlink:href="#MJX-1-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(12161.6,0)"><use data-c="1D452" xlink:href="#MJX-1-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(12627.6,0)"><use data-c="1D460" xlink:href="#MJX-1-TEX-I-1D460"></use></g><g data-mml-node="mi" transform="translate(13096.6,0)"><use data-c="1D460" xlink:href="#MJX-1-TEX-I-1D460"></use></g><g data-mml-node="mtext" transform="translate(13565.6,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(13815.6,0)"><use data-c="1D443" xlink:href="#MJX-1-TEX-I-1D443"></use></g><g data-mml-node="mi" transform="translate(14566.6,0)"><use data-c="1D452" xlink:href="#MJX-1-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(15032.6,0)"><use data-c="1D45F" xlink:href="#MJX-1-TEX-I-1D45F"></use></g><g data-mml-node="mtext" transform="translate(15483.6,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use></g><g data-mml-node="mi" transform="translate(15733.6,0)"><use data-c="1D446" xlink:href="#MJX-1-TEX-I-1D446"></use></g><g data-mml-node="mi" transform="translate(16378.6,0)"><use data-c="1D452" xlink:href="#MJX-1-TEX-I-1D452"></use></g><g data-mml-node="mi" transform="translate(16844.6,0)"><use data-c="1D450" xlink:href="#MJX-1-TEX-I-1D450"></use></g><g data-mml-node="mi" transform="translate(17277.6,0)"><use data-c="1D45C" xlink:href="#MJX-1-TEX-I-1D45C"></use></g><g data-mml-node="mi" transform="translate(17762.6,0)"><use data-c="1D45B" xlink:href="#MJX-1-TEX-I-1D45B"></use></g><g data-mml-node="mi" transform="translate(18362.6,0)"><use data-c="1D451" xlink:href="#MJX-1-TEX-I-1D451"></use></g></g></g></svg></mjx-container><ul><li><strong>计算强度上限 I<sub>max</sub></strong>：两个指标相除即可得到计算平台的<strong>计算强度上限</strong>。它描述的是在这个计算平台上，单位内存交换最多用来进行多少次计算。单位是 <code>FLOPs/Byte</code><sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Roofline Model与深度学习模型的性能分析](https://zhuanlan.zhihu.com/p/34204282)">[2]</span></a></sup>。</li></ul><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.991ex;" xmlns="http://www.w3.org/2000/svg" width="9.651ex" height="4.495ex" role="img" focusable="false" viewBox="0 -1107 4265.9 1987" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path><path id="MJX-1-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-1-TEX-I-1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path id="MJX-1-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-1-TEX-I-1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path><path id="MJX-1-TEX-I-1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D43C" xlink:href="#MJX-1-TEX-I-1D43C"></use></g><g data-mml-node="TeXAtom" transform="translate(473,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D45A" xlink:href="#MJX-1-TEX-I-1D45A"></use></g><g data-mml-node="mi" transform="translate(878,0)"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mi" transform="translate(1407,0)"><use data-c="1D465" xlink:href="#MJX-1-TEX-I-1D465"></use></g></g></g><g data-mml-node="mo" transform="translate(2200.1,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="mfrac" transform="translate(3255.9,0)"><g data-mml-node="mi" transform="translate(220,676)"><use data-c="1D70B" xlink:href="#MJX-1-TEX-I-1D70B"></use></g><g data-mml-node="mi" transform="translate(222,-686)"><use data-c="1D6FD" xlink:href="#MJX-1-TEX-I-1D6FD"></use></g><rect width="770" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><blockquote><p>注：这里所说的“内存”是广义上的内存。对于 CPU 计算平台而言指的就是真正的内存；而对于 GPU 计算平台指的则是显存<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="[Roofline Model与深度学习模型的性能分析](https://zhuanlan.zhihu.com/p/34204282)">[2]</span></a></sup>。</p></blockquote><h2 id="1-2-对朴素实现的观察"><a href="#1-2-对朴素实现的观察" class="headerlink" title="1.2 对朴素实现的观察"></a>1.2 对朴素实现的观察</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">/* Naive reference implementation for correctness testing (single-threaded)</span><br><span class="hljs-comment"> * Operation: C = A * B^T + C</span><br><span class="hljs-comment"> * * Dimensions:</span><br><span class="hljs-comment"> * C: [M, N]</span><br><span class="hljs-comment"> * A: [M, K]</span><br><span class="hljs-comment"> * B: [N, K]</span><br><span class="hljs-comment"> * * Layout:</span><br><span class="hljs-comment"> * Matrices A, B, and C are stored in row-major order.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">matmul_ref</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *A, <span class="hljs-type">const</span> <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">size_t</span> M, <span class="hljs-type">size_t</span> N, <span class="hljs-type">size_t</span> K)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; M; ++i) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> j = <span class="hljs-number">0</span>; j &lt; N; ++j) &#123;<br>            <span class="hljs-type">float</span> sum = <span class="hljs-number">0.0f</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> k = <span class="hljs-number">0</span>; k &lt; K; ++k) &#123;<br>                <span class="hljs-comment">// A[i][k] * B[j][k] (Accessing B as N*K row-major)</span><br>                sum += A[i * K + k] * B[j * K + k];<br>            &#125;<br>            C[i * N + j] += sum;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>计算量与访存量分析：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">对于 C[M, N] 中每一个元素 C[i,j] 的计算：<br>  • 需要读取：A[i, 0:K]（K 个元素）+ B[j, 0:K]（K 个元素）<br>  • 需要计算：K 次乘法 + K 次加法<br><br>总计算量 = M × N × 2K = 2MNK FLOPs<br><br>总访存量（最坏情况，无缓存复用）：<br>  • 读取 A：每个 C[i,j] 读取 K 个 float = M × N × K × 4 bytes<br>  • 读取 B：每个 C[i,j] 读取 K 个 float = M × N × K × 4 bytes  <br>  • 写入 C：M × N × 4 bytes<br>  = (2MNK + MN) × 4 bytes ≈ 8MNK bytes<br><br>计算访存比 = 2MNK / 8MNK = 0.25 FLOPs/Byte<br></code></pre></td></tr></table></figure><p><strong>与 Roofline 拐点对比：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">内存带宽 ≈ 170 GB/s（DDR4 双通道）<br>计算峰值 ≈ 140 GFLOPS（单核基频）<br><br>Roofline 拐点 = 140 / 170 = 0.82 FLOPs/Byte<br><br>朴素实现：0.25 FLOPs/Byte &lt; 0.82 FLOPs/Byte<br>→ 处于 Memory Bound 区域<br></code></pre></td></tr></table></figure><p><strong>问题总结：</strong></p><table><thead><tr><th>问题</th><th>原因</th><th>影响</th></tr></thead><tbody><tr><td>计算访存比极低</td><td>无数据复用，每个元素重复加载</td><td>受限于内存带宽</td></tr><tr><td>无 SIMD</td><td>标量操作</td><td>浪费 16 倍算力</td></tr><tr><td>无指令并行</td><td>循环依赖（C[i][j] 累加）</td><td>流水线停顿</td></tr></tbody></table><p><strong>理想情况：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">优化后（理想情况，每个元素只加载一次）：<br>  计算量 = 2MNK（不变）<br>  访存量 = 读取 A + 读取 B + 读写 C<br>        = (MK + NK + 2MN) × 4 bytes<br><br>当 M = N = K 时：<br>  计算量 = 2N³<br>  访存量 ≈ 4 × 4N² = 16N² bytes<br>  <br>  计算访存比 = 2N³ / 16N² = N/8 FLOPs/Byte<br><br>即计算访存比与矩阵维度 N 成正比，记为 O(N)。<br></code></pre></td></tr></table></figure><p><strong>优化的核心目标：</strong> 通过分块和数据复用，将计算访存比从 0.25 提升到接近 O(N)，让算法从 Memory Bound 转变为 Compute Bound。</p><h1 id="第二部分：优化策略全景"><a href="#第二部分：优化策略全景" class="headerlink" title="第二部分：优化策略全景"></a>第二部分：优化策略全景</h1><p><strong>🚀 GEMM 优化技术栈演进路线</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">🏁 Level 0  朴素实现<br>   └─ 基准版本（无优化）<br><br>⚡ Level 1  SIMD 向量化（AVX2 / AVX-512）<br>   └─ 6 ~ 7 GFLOPS<br><br>📦 Level 2  Loop tiling（基础分块，提高局部性）<br>   └─ ~ 20 GFLOPS<br><br>⚙️ Level 3  多级缓存分块 + 数据打包 + 寄存器分块<br>   └─ ~110 GFLOPS（≈78% Peak，82% OpenBLAS）<br><br>🔥 Level 4  多线程并行（OpenMP）<br>   └─ ~ 1909 GFLOPS（24 核全力输出）<br></code></pre></td></tr></table></figure><p><strong>Level 3 优化技术：</strong></p><ul><li>Multi-level cache blocking：根据 L1&#x2F;L2&#x2F;L3 容量设计分块参数（MC, NC, KC），精确控制数据驻留层级</li><li>Data packing：将分块数据重排为连续内存布局，提升 cache line 利用率和预取效率</li><li>Register blocking：设计 14×32 微内核，最大化 ZMM 寄存器复用，采用外积累加消除数据依赖</li></ul><p><strong>基线测试结果</strong></p><table><thead><tr><th>Kernel</th><th>描述</th><th>Peak GFLOPS</th><th>Avg GFLOPS</th></tr></thead><tbody><tr><td><code>core_v1_avx2</code></td><td>AVX2 向量化内层循环</td><td>6.42</td><td>6.35</td></tr><tr><td><code>core_v2_avx512</code></td><td>AVX-512 向量化内层循环</td><td>7.12</td><td>7.07</td></tr><tr><td><code>core_v3_block</code></td><td>简单 2D 循环分块</td><td>19.74</td><td>19.73</td></tr></tbody></table><blockquote><p>注意：AVX-512 相比 AVX2 提升很小，因为此时内核是访存瓶颈——单纯增加计算吞吐而不优化内存访问模式，收益微乎其微。</p></blockquote><p><strong>源码链接</strong></p><ul><li><code>core_v1_avx2:</code> <a href="https://github.com/tianyuxbear/matmul-cpu/blob/master/src/core/matmul_v1_av2.cpp">https://github.com/tianyuxbear/matmul-cpu/blob/master/src/core/matmul_v1_av2.cpp</a></li><li><code>core_v2_avx512:</code> <a href="https://github.com/tianyuxbear/matmul-cpu/blob/master/src/core/matmul_v2_avx512.cpp">https://github.com/tianyuxbear/matmul-cpu/blob/master/src/core/matmul_v2_avx512.cpp</a></li><li><code>core_v3_block:</code> <a href="https://github.com/tianyuxbear/matmul-cpu/blob/master/src/core/matmul_v3_avx512_block.cpp">https://github.com/tianyuxbear/matmul-cpu/blob/master/src/core/matmul_v3_avx512_block.cpp</a></li></ul><div class="note note-info">            <ul> <li>SIMD向量化一条指令可以处理 8&#x2F;16 个float，提高了计算吞吐。</li> <li>基础分块提升局部性的本质：通过减小工作集大小，让数据驻留在更快的缓存层级中，被多次复用后再换出。</li> </ul>           </div><h1 id="第三部分：基础分块优势"><a href="#第三部分：基础分块优势" class="headerlink" title="第三部分：基础分块优势"></a>第三部分：基础分块优势</h1><h2 id="3-1-朴素版本的问题"><a href="#3-1-朴素版本的问题" class="headerlink" title="3.1 朴素版本的问题"></a>3.1 朴素版本的问题</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 假设 M=1024, N=1024, K=1024</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; M; i++) &#123;       <span class="hljs-comment">// 1024 次</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; N; j++) &#123;   <span class="hljs-comment">// 1024 次</span><br>        <span class="hljs-built_in">dot_product</span>(A[i], B[j]);    <span class="hljs-comment">// 每次读取 K=1024 个元素</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>内存访问分析：</strong></p><table><thead><tr><th>矩阵</th><th>每次内循环读取</th><th>总读取次数</th><th>总数据量</th></tr></thead><tbody><tr><td>A[i]</td><td>K 个元素</td><td>M × N 次</td><td>M × N × K</td></tr><tr><td>B[j]</td><td>K 个元素</td><td>M × N 次</td><td>M × N × K</td></tr></tbody></table><p><strong>问题所在：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">外循环 i=0 时：<br>  j=0: 读 A[0], B[0]<br>  j=1: 读 A[0], B[1]    ← A[0] 重复读取，但 B 在快速变化<br>  j=2: 读 A[0], B[2]<br>  ...<br>  j=1023: 读 A[0], B[1023]<br>  <br>外循环 i=1 时：<br>  j=0: 读 A[1], B[0]    ← B[0] 又要重新读！之前早被踢出缓存了<br>  j=1: 读 A[1], B[1]<br></code></pre></td></tr></table></figure><p><strong>B 矩阵的每一行被读取了 M 次，但由于 B 太大无法全部放入缓存，每次都要从主存重新加载！</strong></p><h2 id="3-2-分块版本的优势"><a href="#3-2-分块版本的优势" class="headerlink" title="3.2 分块版本的优势"></a>3.2 分块版本的优势</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 完整的分块矩阵乘法</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TILE 16</span><br><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i0 = <span class="hljs-number">0</span>; i0 &lt; M; i0 += TILE) &#123;           <span class="hljs-comment">// 遍历 A 的行块</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j0 = <span class="hljs-number">0</span>; j0 &lt; N; j0 += TILE) &#123;       <span class="hljs-comment">// 遍历 B 的行块</span><br>        <span class="hljs-comment">// 处理 C[i0:i0+TILE, j0:j0+TILE] 这个子块</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = i0; i &lt; i0 + TILE; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = j0; j &lt; j0 + TILE; j++) &#123;<br>                C[i][j] = <span class="hljs-built_in">dot_product</span>(A[i], B[j]);<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>假设：M&#x3D;N&#x3D;K&#x3D;1024，TILE&#x3D;16，每个元素 4 字节</p></blockquote><p><strong>朴素版本内存访问：</strong></p><p>处理整个矩阵：</p><ul><li>A 总读取：M × N × K × 4 bytes &#x3D; 1024 × 1024 × 1024 × 4 &#x3D; 4 GB</li><li>B 总读取：M × N × K × 4 bytes &#x3D; 4 GB</li><li>总计：8 GB 数据传输</li></ul><p><strong>分块版本内存访问：</strong></p><p>处理一个 16×16 的 C 子块：</p><ul><li>需要 A 的 16 行：16 × 1024 × 4 &#x3D; 64 KB</li><li>需要 B 的 16 行：16 × 1024 × 4 &#x3D; 64 KB</li><li><strong>这 128 KB 可以放入 L2 Cache！</strong></li></ul><p>整个矩阵有 (1024&#x2F;16) × (1024&#x2F;16) &#x3D; 4096 个子块</p><ul><li>A 的每行被读取 1024&#x2F;16 &#x3D; 64 次（分布在 64 个列方向的子块中）</li><li>B 的每行被读取 1024&#x2F;16 &#x3D; 64 次（分布在 64 个行方向的子块中）</li></ul><p>总数据传输：</p><ul><li>A：M × K × (N&#x2F;TILE) × 4 &#x3D; 1024 × 1024 × 64 × 4 &#x3D; 256 MB</li><li>B：N × K × (M&#x2F;TILE) × 4 &#x3D; 256 MB</li><li>总计：512 MB</li></ul><p>相比朴素版本的 8 GB，减少了 16 倍！（恰好等于 TILE 大小）</p><p><strong>图示理解</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">朴素版本：缓存不断被刷新<br>═══════════════════════════════════════<br><br>时间 t1: Cache = [A[0], B[0], B[1], B[2]...]<br>时间 t2: Cache = [A[0], B[100], B[101]...]  ← B[0-99] 被踢出<br>时间 t3: Cache = [A[1], B[0], B[1]...]      ← 需要重新加载 B[0]！<br>                  ↑ <br>                  A[0] 也被踢出了<br><br>分块版本：数据留在缓存中被反复使用<br>═══════════════════════════════════════<br><br>处理子块 (0,0):<br>Cache = [A[0:16], B[0:16]]  ← 加载一次<br>        ↓<br>        16×16=256 次点积全部命中缓存！<br>        <br>处理子块 (0,1):<br>Cache = [A[0:16], B[16:32]]  ← A[0:16] 已在缓存！只需加载新的 B<br></code></pre></td></tr></table></figure><p><strong>分块的三大优势</strong></p><table><thead><tr><th>优势</th><th>说明</th></tr></thead><tbody><tr><td>1. 缓存命中率↑</td><td>小块数据能放入缓存，反复使用不被踢出</td></tr><tr><td>2. 内存带宽需求↓</td><td>总数据传输量降低 TILE 倍</td></tr><tr><td>3. 计算访存比↑</td><td>同样的数据量产生更多计算，更接近硬件算力峰值</td></tr></tbody></table><div class="note note-success">            <p>在 GPU 上，分块更加关键——因为 GPU 有专门的 Shared Memory（共享内存），分块可以让数据从慢速的 Global Memory 加载到快速的 Shared Memory，大幅提升性能。这正是 CUDA 矩阵乘法优化的核心思想。</p>           </div><h1 id="第四部分：寄存器分块——微内核设计"><a href="#第四部分：寄存器分块——微内核设计" class="headerlink" title="第四部分：寄存器分块——微内核设计"></a>第四部分：寄存器分块——微内核设计</h1><p>阅读本文以下内容前，请务必通读参考链接3<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="[现代多核处理器上的高级矩阵乘法优化](https://mp.weixin.qq.com/s/hARNYew5nluJB_bk9_1qZA)">[3]</span></a></sup>的文章内容，对计算内核的外积计算方式以及缓存分块技术有一定了解。</p><h2 id="4-1-寄存器资源分析"><a href="#4-1-寄存器资源分析" class="headerlink" title="4.1 寄存器资源分析"></a>4.1 寄存器资源分析</h2><p>AVX-512 提供 32 个 512-bit 的 ZMM 寄存器，每个可存储 16 个 float。微内核（micro-kernel）的目标是<strong>最大化寄存器利用率</strong>，让尽可能多的数据驻留在寄存器中。</p><h2 id="4-2-分块尺寸推导"><a href="#4-2-分块尺寸推导" class="headerlink" title="4.2 分块尺寸推导"></a>4.2 分块尺寸推导</h2><p>设微内核计算 C 的一个 MR × NR 子块：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">寄存器分配：<br>- C 累加器：MR × (NR / 16) 个 ZMM<br>- A 广播寄存器：1 个 ZMM<br>- B 数据寄存器：NR / 16 个 ZMM<br>- 临时寄存器：≥ 1 个<br></code></pre></td></tr></table></figure><p><strong>约束条件：</strong></p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.602ex;" xmlns="http://www.w3.org/2000/svg" width="28.498ex" height="4.131ex" role="img" focusable="false" viewBox="0 -1118 12596 1826" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-N-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path id="MJX-1-TEX-I-1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-I-1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path><path id="MJX-1-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-1-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-1-TEX-N-2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path><path id="MJX-1-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-1-TEX-N-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path id="MJX-1-TEX-N-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path id="MJX-1-TEX-N-3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path><path id="MJX-1-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-1-TEX-N-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path id="MJX-1-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><use data-c="28" xlink:href="#MJX-1-TEX-N-28"></use></g><g data-mml-node="mfrac" transform="translate(389,0)"><g data-mml-node="msub" transform="translate(220,676)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-1-TEX-I-1D45B"></use></g><g data-mml-node="mi" transform="translate(633,-150) scale(0.707)"><use data-c="1D445" xlink:href="#MJX-1-TEX-I-1D445"></use></g></g><g data-mml-node="mn" transform="translate(329.8,-686)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use><use data-c="36" xlink:href="#MJX-1-TEX-N-36" transform="translate(500,0)"></use></g><rect width="1419.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(2270.9,0)"><use data-c="2217" xlink:href="#MJX-1-TEX-N-2217"></use></g><g data-mml-node="msub" transform="translate(2993.1,0)"><g data-mml-node="mi"><use data-c="1D45A" xlink:href="#MJX-1-TEX-I-1D45A"></use></g><g data-mml-node="mi" transform="translate(911,-150) scale(0.707)"><use data-c="1D445" xlink:href="#MJX-1-TEX-I-1D445"></use></g></g><g data-mml-node="mo" transform="translate(4713.1,0)"><use data-c="2B" xlink:href="#MJX-1-TEX-N-2B"></use></g><g data-mml-node="mfrac" transform="translate(5713.3,0)"><g data-mml-node="msub" transform="translate(220,676)"><g data-mml-node="mi"><use data-c="1D45B" xlink:href="#MJX-1-TEX-I-1D45B"></use></g><g data-mml-node="mi" transform="translate(633,-150) scale(0.707)"><use data-c="1D445" xlink:href="#MJX-1-TEX-I-1D445"></use></g></g><g data-mml-node="mn" transform="translate(329.8,-686)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use><use data-c="36" xlink:href="#MJX-1-TEX-N-36" transform="translate(500,0)"></use></g><rect width="1419.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(7595.2,0)"><use data-c="2B" xlink:href="#MJX-1-TEX-N-2B"></use></g><g data-mml-node="mn" transform="translate(8595.4,0)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use></g><g data-mml-node="mo" transform="translate(9095.4,0)"><use data-c="29" xlink:href="#MJX-1-TEX-N-29"></use></g><g data-mml-node="mo" transform="translate(9762.2,0)"><g data-mml-node="text"><use data-c="3C" xlink:href="#MJX-1-TEX-N-3C"></use></g><g data-mml-node="text" transform="translate(778,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g></g><g data-mml-node="mn" transform="translate(11596,0)"><use data-c="33" xlink:href="#MJX-1-TEX-N-33"></use><use data-c="32" xlink:href="#MJX-1-TEX-N-32" transform="translate(500,0)"></use></g></g></g></svg></mjx-container><blockquote><p>注：因为本文是基于行主序实现，所以要求<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.373ex;" xmlns="http://www.w3.org/2000/svg" width="3.219ex" height="1.918ex" role="img" focusable="false" viewBox="0 -683 1422.7 847.8" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path id="MJX-1-TEX-I-1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D441" xlink:href="#MJX-1-TEX-I-1D441"></use></g><g data-mml-node="mi" transform="translate(836,-150) scale(0.707)"><use data-c="1D445" xlink:href="#MJX-1-TEX-I-1D445"></use></g></g></g></g></svg></mjx-container>一定是16的整数倍，便于写入分块的 C[MR, NR]。</p></blockquote><p><strong>两种可行配置：</strong></p><table><thead><tr><th>配置</th><th>C 寄存器</th><th>A</th><th>B</th><th>临时</th><th>总计</th><th>每迭代 FMA</th></tr></thead><tbody><tr><td>MR&#x3D;30, NR&#x3D;16</td><td>30</td><td>1</td><td>1</td><td>0</td><td>32</td><td>30</td></tr><tr><td>MR&#x3D;14, NR&#x3D;32</td><td>28</td><td>1</td><td>2</td><td>1</td><td>32</td><td>28</td></tr></tbody></table><h2 id="4-3-为什么选择-MR-14-NR-32？"><a href="#4-3-为什么选择-MR-14-NR-32？" class="headerlink" title="4.3 为什么选择 MR&#x3D;14, NR&#x3D;32？"></a>4.3 为什么选择 MR&#x3D;14, NR&#x3D;32？</h2><p>虽然 30×16 配置的 FMA 数量更多，但实测 14×32 性能更优，原因如下：</p><h3 id="a-端口竞争分析"><a href="#a-端口竞争分析" class="headerlink" title="a. 端口竞争分析"></a>a. 端口竞争分析</h3><p>每次 K 迭代的指令分布：</p><p>配置 30×16：</p><ul><li>Broadcast: 30 次 → Port 5，需要 30 cycles</li><li>FMA: 30 次 → Port 0&#x2F;1，需要 15 cycles</li><li>Load: 1 次 → Port 2&#x2F;3，需要 0.5 cycle</li></ul><p>→ Port 5 成为瓶颈！</p><p>配置 14×32：</p><ul><li>Broadcast: 14 次 → Port 5，需要 14 cycles</li><li>FMA: 28 次 → Port 0&#x2F;1，需要 14 cycles</li><li>Load: 2 次 → Port 2&#x2F;3，需要 1 cycle</li></ul><p>→ FMA 和 Broadcast 平衡！</p><blockquote><p>注：此部分为claude的分析结果，Broadcast、FMA、Load的计算次数是正确的，Inst Issue Port和Latency尚未查证。</p></blockquote><h3 id="b-Cache-Line-利用率"><a href="#b-Cache-Line-利用率" class="headerlink" title="b. Cache Line 利用率"></a>b. Cache Line 利用率</h3><p>14×32 配置：</p><ul><li>B 每次加载 32 float &#x3D; 128 bytes &#x3D; 2 个完整 cache line ✓</li></ul><p>30×16 配置：</p><ul><li>B 每次加载 16 float &#x3D; 64 bytes &#x3D; 1 个 cache line ✓</li><li>但 A 需要 30 float &#x3D; 120 bytes，跨 2 个 cache line，可能有浪费</li></ul><h2 id="4-4-微内核代码实现"><a href="#4-4-微内核代码实现" class="headerlink" title="4.4 微内核代码实现"></a>4.4 微内核代码实现</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @brief The Core FMA Loop.</span><br><span class="hljs-comment"> * Computes 14x32 block dot product over the K-dimension (size kc).</span><br><span class="hljs-comment"> * Uses explicit loop unrolling for maximum pipeline utilization.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">fma_loop</span><span class="hljs-params">(<span class="hljs-type">float</span> *packedA, <span class="hljs-type">float</span> *packedB,</span></span><br><span class="hljs-params"><span class="hljs-function">                            __m512 C_accum[MR][<span class="hljs-number">2</span>],</span></span><br><span class="hljs-params"><span class="hljs-function">                            __m512 *va, __m512 *vb0, __m512 *vb1, <span class="hljs-type">int</span> kc)</span> </span>&#123;<br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; kc; ++k) &#123;<br>        <span class="hljs-comment">// Load 32 elements of B (2 ZMMs)</span><br>        <span class="hljs-comment">// Since B is packed, these are sequential loads.</span><br>        *vb0 = _mm512_loadu_ps(packedB);<br>        *vb1 = _mm512_loadu_ps(packedB + <span class="hljs-number">16</span>);<br><br><span class="hljs-comment">// Broadcast A elements and multiply-add</span><br><span class="hljs-comment">// Unrolling MR (14) times</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UNROLL_FMA(i)                                          \</span><br><span class="hljs-meta">    *va = _mm512_set1_ps(packedA[i]);                          \</span><br><span class="hljs-meta">    C_accum[i][0] = _mm512_fmadd_ps(*va, *vb0, C_accum[i][0]); \</span><br><span class="hljs-meta">    C_accum[i][1] = _mm512_fmadd_ps(*va, *vb1, C_accum[i][1]);</span><br><br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">0</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">1</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">2</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">3</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">4</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">5</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">6</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">7</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">8</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">9</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">10</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">11</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">12</span>);<br>        <span class="hljs-built_in">UNROLL_FMA</span>(<span class="hljs-number">13</span>);<br><br><span class="hljs-meta">#<span class="hljs-keyword">undef</span> UNROLL_FMA</span><br><br>        <span class="hljs-comment">// Advance pointers</span><br>        <span class="hljs-comment">// A moves by MR (14 floats), B moves by NR (32 floats)</span><br>        packedA += MR;<br>        packedB += NR;<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @brief The Micro-Kernel.</span><br><span class="hljs-comment"> * Manages register allocation, accumulation, and boundary masking.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">micro_kernel</span><span class="hljs-params">(<span class="hljs-type">float</span> *packedA, <span class="hljs-type">float</span> *packedB, <span class="hljs-type">float</span> *C,</span></span><br><span class="hljs-params"><span class="hljs-function">                                <span class="hljs-type">int</span> mr, <span class="hljs-type">int</span> nr, <span class="hljs-type">int</span> kc, <span class="hljs-type">int</span> N_stride)</span> </span>&#123;<br><br>    __m512 C_accum[MR][<span class="hljs-number">2</span>];        <span class="hljs-comment">// 28 Registers used for Accumulation</span><br>    __m512 a_reg, b0_reg, b1_reg; <span class="hljs-comment">// 3 Registers for operands</span><br>    <span class="hljs-comment">// Total regs used: ~31 (fits in 32 ZMMs)</span><br><br>    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(nr == NR)) &#123;<br>        <span class="hljs-built_in">load_accum</span>(C, C_accum, N_stride, mr);<br>        <span class="hljs-built_in">fma_loop</span>(packedA, packedB, C_accum, &amp;a_reg, &amp;b0_reg, &amp;b1_reg, kc);<br>        <span class="hljs-built_in">store_accum</span>(C, C_accum, N_stride, mr);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// Boundary handling with masks</span><br>        __mmask16 mask0 = <span class="hljs-built_in">create_mask</span>(nr);<br>        __mmask16 mask1 = <span class="hljs-built_in">create_mask</span>(nr - <span class="hljs-number">16</span>);<br><br>        <span class="hljs-built_in">maskload_accum</span>(C, C_accum, N_stride, mr, mask0, mask1);<br>        <span class="hljs-built_in">fma_loop</span>(packedA, packedB, C_accum, &amp;a_reg, &amp;b0_reg, &amp;b1_reg, kc);<br>        <span class="hljs-built_in">maskstore_accum</span>(C, C_accum, N_stride, mr, mask0, mask1);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="4-5-外积（Rank-1-Update）的数学本质"><a href="#4-5-外积（Rank-1-Update）的数学本质" class="headerlink" title="4.5 外积（Rank-1 Update）的数学本质"></a>4.5 外积（Rank-1 Update）的数学本质</h2><p>矩阵乘法可以分解为 K 次 Rank-1 Update：</p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.864ex;" xmlns="http://www.w3.org/2000/svg" width="26.327ex" height="6.784ex" role="img" focusable="false" viewBox="0 -1733 11636.4 2998.7" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-I-1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path><path id="MJX-1-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-1-TEX-I-1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path><path id="MJX-1-TEX-I-1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path id="MJX-1-TEX-I-1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path id="MJX-1-TEX-LO-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path><path id="MJX-1-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-1-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-1-TEX-I-1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path><path id="MJX-1-TEX-N-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path id="MJX-1-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-1-TEX-N-3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path id="MJX-1-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-1-TEX-N-2297" d="M56 250Q56 394 156 488T384 583Q530 583 626 485T722 250Q722 110 625 14T390 -83Q249 -83 153 14T56 250ZM582 471Q531 510 496 523Q446 542 381 542Q324 542 272 519T196 471L389 278L485 375L582 471ZM167 442Q95 362 95 250Q95 137 167 58L359 250L167 442ZM610 58Q682 138 682 250Q682 363 610 442L418 250L610 58ZM196 29Q209 16 230 2T295 -27T388 -42Q409 -42 429 -40T465 -33T496 -23T522 -11T544 1T561 13T574 22T582 29L388 222L196 29Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><use data-c="1D436" xlink:href="#MJX-1-TEX-I-1D436"></use></g><g data-mml-node="mo" transform="translate(1037.8,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="mi" transform="translate(2093.6,0)"><use data-c="1D434" xlink:href="#MJX-1-TEX-I-1D434"></use></g><g data-mml-node="msup" transform="translate(2843.6,0)"><g data-mml-node="mi"><use data-c="1D435" xlink:href="#MJX-1-TEX-I-1D435"></use></g><g data-mml-node="TeXAtom" transform="translate(792,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D447" xlink:href="#MJX-1-TEX-I-1D447"></use></g></g></g><g data-mml-node="mo" transform="translate(4461.1,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="munderover" transform="translate(5516.9,0)"><g data-mml-node="mo" transform="translate(44.2,0)"><use data-c="2211" xlink:href="#MJX-1-TEX-LO-2211"></use></g><g data-mml-node="TeXAtom" transform="translate(130.1,-1107.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D458" xlink:href="#MJX-1-TEX-I-1D458"></use></g><g data-mml-node="mo" transform="translate(521,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1299,0)"><use data-c="30" xlink:href="#MJX-1-TEX-N-30"></use></g></g><g data-mml-node="TeXAtom" transform="translate(0,1150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><use data-c="1D43E" xlink:href="#MJX-1-TEX-I-1D43E"></use></g><g data-mml-node="mo" transform="translate(889,0)"><use data-c="2212" xlink:href="#MJX-1-TEX-N-2212"></use></g><g data-mml-node="mn" transform="translate(1667,0)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use></g></g></g><g data-mml-node="msub" transform="translate(7215.9,0)"><g data-mml-node="mi"><use data-c="1D434" xlink:href="#MJX-1-TEX-I-1D434"></use></g><g data-mml-node="TeXAtom" transform="translate(783,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><use data-c="3A" xlink:href="#MJX-1-TEX-N-3A"></use></g><g data-mml-node="mo" transform="translate(278,0)"><use data-c="2C" xlink:href="#MJX-1-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(556,0)"><use data-c="1D458" xlink:href="#MJX-1-TEX-I-1D458"></use></g></g></g><g data-mml-node="mo" transform="translate(9032.7,0)"><use data-c="2297" xlink:href="#MJX-1-TEX-N-2297"></use></g><g data-mml-node="msub" transform="translate(10032.9,0)"><g data-mml-node="mi"><use data-c="1D435" xlink:href="#MJX-1-TEX-I-1D435"></use></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><use data-c="3A" xlink:href="#MJX-1-TEX-N-3A"></use></g><g data-mml-node="mo" transform="translate(278,0)"><use data-c="2C" xlink:href="#MJX-1-TEX-N-2C"></use></g><g data-mml-node="mi" transform="translate(556,0)"><use data-c="1D458" xlink:href="#MJX-1-TEX-I-1D458"></use></g></g></g></g></g></svg></mjx-container><p>其中 ⊗ 表示外积：</p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -4.604ex;" xmlns="http://www.w3.org/2000/svg" width="59.954ex" height="10.339ex" role="img" focusable="false" viewBox="0 -2535 26499.7 4570" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-1-TEX-S4-23A1" d="M319 -645V1154H666V1070H403V-645H319Z"></path><path id="MJX-1-TEX-S4-23A3" d="M319 -644V1155H403V-560H666V-644H319Z"></path><path id="MJX-1-TEX-S4-23A2" d="M319 0V602H403V0H319Z"></path><path id="MJX-1-TEX-I-1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path id="MJX-1-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-1-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-1-TEX-N-22EE" d="M78 30Q78 54 95 72T138 90Q162 90 180 74T199 31Q199 6 182 -12T139 -30T96 -13T78 30ZM78 440Q78 464 95 482T138 500Q162 500 180 484T199 441Q199 416 182 398T139 380T96 397T78 440ZM78 840Q78 864 95 882T138 900Q162 900 180 884T199 841Q199 816 182 798T139 780T96 797T78 840Z"></path><path id="MJX-1-TEX-S4-23A4" d="M0 1070V1154H347V-645H263V1070H0Z"></path><path id="MJX-1-TEX-S4-23A6" d="M263 -560V1155H347V-644H0V-560H263Z"></path><path id="MJX-1-TEX-S4-23A5" d="M263 0V602H347V0H263Z"></path><path id="MJX-1-TEX-N-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path id="MJX-1-TEX-I-1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path><path id="MJX-1-TEX-N-2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path><path id="MJX-1-TEX-N-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path id="MJX-1-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-1-TEX-N-22F1" d="M133 760Q133 784 150 802T193 820Q217 820 235 804T254 761Q254 736 237 718T194 700T151 717T133 760ZM580 460Q580 484 597 502T640 520Q664 520 682 504T701 461Q701 436 684 418T641 400T598 417T580 460ZM1027 160Q1027 184 1044 202T1087 220Q1111 220 1129 204T1148 161Q1148 136 1131 118T1088 100T1045 117T1027 160Z"></path><path id="MJX-1-TEX-N-2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path><path id="MJX-1-TEX-N-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path><path id="MJX-1-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-1-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-1-TEX-N-6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z"></path><path id="MJX-1-TEX-N-2D" d="M11 179V252H277V179H11Z"></path><path id="MJX-1-TEX-N-20" d=""></path><path id="MJX-1-TEX-N-4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path><path id="MJX-1-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-1-TEX-N-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path id="MJX-1-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-1-TEX-N-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo"><use data-c="23A1" xlink:href="#MJX-1-TEX-S4-23A1" transform="translate(0,1271)"></use><use data-c="23A3" xlink:href="#MJX-1-TEX-S4-23A3" transform="translate(0,-1281)"></use><svg width="667" height="952" y="-226" x="0" viewBox="0 238 667 952"><use data-c="23A2" xlink:href="#MJX-1-TEX-S4-23A2" transform="scale(1,2.372)"></use></svg></g><g data-mml-node="mtable" transform="translate(667,0)"><g data-mml-node="mtr" transform="translate(0,1675)"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mn" transform="translate(562,-150) scale(0.707)"><use data-c="30" xlink:href="#MJX-1-TEX-N-30"></use></g></g></g></g><g data-mml-node="mtr" transform="translate(0,275)"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mn" transform="translate(562,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use></g></g></g></g><g data-mml-node="mtr" transform="translate(0,-1675)"><g data-mml-node="mtd" transform="translate(343.8,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo"><use data-c="22EE" xlink:href="#MJX-1-TEX-N-22EE"></use></g></g></g></g></g><g data-mml-node="mo" transform="translate(1632.6,0)"><use data-c="23A4" xlink:href="#MJX-1-TEX-S4-23A4" transform="translate(0,1271)"></use><use data-c="23A6" xlink:href="#MJX-1-TEX-S4-23A6" transform="translate(0,-1281)"></use><svg width="667" height="952" y="-226" x="0" viewBox="0 238 667 952"><use data-c="23A5" xlink:href="#MJX-1-TEX-S4-23A5" transform="scale(1,2.372)"></use></svg></g></g><g data-mml-node="mrow" transform="translate(2466.2,0)"><g data-mml-node="mo"><use data-c="5B" xlink:href="#MJX-1-TEX-N-5B"></use></g><g data-mml-node="mtable" transform="translate(278,0)"><g data-mml-node="mtr"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-1-TEX-I-1D44F"></use></g><g data-mml-node="mn" transform="translate(462,-150) scale(0.707)"><use data-c="30" xlink:href="#MJX-1-TEX-N-30"></use></g></g></g><g data-mml-node="mtd" transform="translate(1865.6,0)"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-1-TEX-I-1D44F"></use></g><g data-mml-node="mn" transform="translate(462,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use></g></g></g><g data-mml-node="mtd" transform="translate(3731.1,0)"><g data-mml-node="mo"><use data-c="2026" xlink:href="#MJX-1-TEX-N-2026"></use></g></g></g></g><g data-mml-node="mo" transform="translate(5181.1,0)"><use data-c="5D" xlink:href="#MJX-1-TEX-N-5D"></use></g></g><g data-mml-node="mo" transform="translate(8203.1,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="mrow" transform="translate(9258.9,0)"><g data-mml-node="mo"><use data-c="23A1" xlink:href="#MJX-1-TEX-S4-23A1" transform="translate(0,1381)"></use><use data-c="23A3" xlink:href="#MJX-1-TEX-S4-23A3" transform="translate(0,-1391)"></use><svg width="667" height="1172" y="-336" x="0" viewBox="0 293 667 1172"><use data-c="23A2" xlink:href="#MJX-1-TEX-S4-23A2" transform="scale(1,2.92)"></use></svg></g><g data-mml-node="mtable" transform="translate(667,0)"><g data-mml-node="mtr" transform="translate(0,1785)"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mn" transform="translate(562,-150) scale(0.707)"><use data-c="30" xlink:href="#MJX-1-TEX-N-30"></use></g></g><g data-mml-node="msub" transform="translate(965.6,0)"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-1-TEX-I-1D44F"></use></g><g data-mml-node="mn" transform="translate(462,-150) scale(0.707)"><use data-c="30" xlink:href="#MJX-1-TEX-N-30"></use></g></g></g><g data-mml-node="mtd" transform="translate(2831.1,0)"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mn" transform="translate(562,-150) scale(0.707)"><use data-c="30" xlink:href="#MJX-1-TEX-N-30"></use></g></g><g data-mml-node="msub" transform="translate(965.6,0)"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-1-TEX-I-1D44F"></use></g><g data-mml-node="mn" transform="translate(462,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use></g></g></g><g data-mml-node="mtd" transform="translate(5717.2,0)"><g data-mml-node="mo"><use data-c="2026" xlink:href="#MJX-1-TEX-N-2026"></use></g></g></g><g data-mml-node="mtr" transform="translate(0,385)"><g data-mml-node="mtd"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mn" transform="translate(562,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use></g></g><g data-mml-node="msub" transform="translate(965.6,0)"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-1-TEX-I-1D44F"></use></g><g data-mml-node="mn" transform="translate(462,-150) scale(0.707)"><use data-c="30" xlink:href="#MJX-1-TEX-N-30"></use></g></g></g><g data-mml-node="mtd" transform="translate(2831.1,0)"><g data-mml-node="msub"><g data-mml-node="mi"><use data-c="1D44E" xlink:href="#MJX-1-TEX-I-1D44E"></use></g><g data-mml-node="mn" transform="translate(562,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use></g></g><g data-mml-node="msub" transform="translate(965.6,0)"><g data-mml-node="mi"><use data-c="1D44F" xlink:href="#MJX-1-TEX-I-1D44F"></use></g><g data-mml-node="mn" transform="translate(462,-150) scale(0.707)"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use></g></g></g><g data-mml-node="mtd" transform="translate(5717.2,0)"><g data-mml-node="mo"><use data-c="2026" xlink:href="#MJX-1-TEX-N-2026"></use></g></g></g><g data-mml-node="mtr" transform="translate(0,-1785)"><g data-mml-node="mtd" transform="translate(776.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo"><use data-c="22EE" xlink:href="#MJX-1-TEX-N-22EE"></use></g></g></g><g data-mml-node="mtd" transform="translate(3607.7,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo"><use data-c="22EE" xlink:href="#MJX-1-TEX-N-22EE"></use></g></g></g><g data-mml-node="mtd" transform="translate(5662.2,0)"><g data-mml-node="mo"><use data-c="22F1" xlink:href="#MJX-1-TEX-N-22F1"></use></g></g></g></g><g data-mml-node="mo" transform="translate(7611.2,0)"><use data-c="23A4" xlink:href="#MJX-1-TEX-S4-23A4" transform="translate(0,1381)"></use><use data-c="23A6" xlink:href="#MJX-1-TEX-S4-23A6" transform="translate(0,-1391)"></use><svg width="667" height="1172" y="-336" x="0" viewBox="0 293 667 1172"><use data-c="23A5" xlink:href="#MJX-1-TEX-S4-23A5" transform="scale(1,2.92)"></use></svg></g></g><g data-mml-node="mstyle" transform="translate(17537.1,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(18814.9,0)"><use data-c="2190" xlink:href="#MJX-1-TEX-N-2190"></use></g><g data-mml-node="mtext" transform="translate(20092.7,0)"><use data-c="52" xlink:href="#MJX-1-TEX-N-52"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(736,0)"></use><use data-c="6E" xlink:href="#MJX-1-TEX-N-6E" transform="translate(1236,0)"></use><use data-c="6B" xlink:href="#MJX-1-TEX-N-6B" transform="translate(1792,0)"></use><use data-c="2D" xlink:href="#MJX-1-TEX-N-2D" transform="translate(2320,0)"></use><use data-c="31" xlink:href="#MJX-1-TEX-N-31" transform="translate(2653,0)"></use><use data-c="20" xlink:href="#MJX-1-TEX-N-20" transform="translate(3153,0)"></use><use data-c="4D" xlink:href="#MJX-1-TEX-N-4D" transform="translate(3403,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(4320,0)"></use><use data-c="74" xlink:href="#MJX-1-TEX-N-74" transform="translate(4820,0)"></use><use data-c="72" xlink:href="#MJX-1-TEX-N-72" transform="translate(5209,0)"></use><use data-c="69" xlink:href="#MJX-1-TEX-N-69" transform="translate(5601,0)"></use><use data-c="78" xlink:href="#MJX-1-TEX-N-78" transform="translate(5879,0)"></use></g></g></g></svg></mjx-container><p><strong>外积相比内积的优势：</strong></p><table><thead><tr><th>方面</th><th>内积</th><th>外积</th></tr></thead><tbody><tr><td>累加器数量</td><td>1 个（当前 C[i,j]）</td><td>MR × NR 个（整个子块）</td></tr><tr><td>累加器位置</td><td>频繁换入换出内存</td><td>全程驻留寄存器</td></tr><tr><td>单次迭代</td><td>计算 1 个 C 元素</td><td>更新 448 个 C 元素</td></tr><tr><td>A 的复用</td><td>被 N 个 B 行复用（跨时间）</td><td>被 NR 个 B 元素复用（同时）</td></tr><tr><td>B 的复用</td><td>无（每个 B 行只用一次）</td><td>被 MR 个 A 元素复用（同时）</td></tr></tbody></table><p><strong>关键区别：</strong> 内积的复用是”跨时间”的（A 行在计算多个 C 元素时被复用，但中间可能被换出 cache），外积的复用是”同时”的（A 和 B 在同一批指令中互相复用，数据就在寄存器里）。</p><h1 id="第五部分：缓存分块——多级存储层次优化"><a href="#第五部分：缓存分块——多级存储层次优化" class="headerlink" title="第五部分：缓存分块——多级存储层次优化"></a>第五部分：缓存分块——多级存储层次优化</h1><p><strong>BLIS设计示意图:</strong></p><blockquote><p>记得回忆一下参考链接3<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="[现代多核处理器上的高级矩阵乘法优化](https://mp.weixin.qq.com/s/hARNYew5nluJB_bk9_1qZA)">[3]</span></a></sup>中的缓存分块内容。</p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/tianyuxbear/images/blog/blis_design.png" alt="blis_design"></p><h2 id="5-1-缓存层次与数据块大小"><a href="#5-1-缓存层次与数据块大小" class="headerlink" title="5.1 缓存层次与数据块大小"></a>5.1 缓存层次与数据块大小</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">/*<br> * ┌──────────────────────────────────────────────────────────────────────┐<br> * │  Goal: Maximize data reuse before eviction (Tiling Strategy)         │<br> * ├─────────────┬──────────────┬──────────────────┬──────────────────────┤<br> * │ Cache Level │ Capacity     │ Data Block       │ Reuse Strategy       │<br> * ├─────────────┼──────────────┼──────────────────┼──────────────────────┤<br> * │ L1 (48KB)   │ Smallest/    │ A[MR, KC]        │ Inside Micro-kernel  │<br> * │             │ Fastest      │ B[NR, KC]        │ Reuse: KC times      │<br> * ├─────────────┼──────────────┼──────────────────┼──────────────────────┤<br> * │ L2 (1.25MB) │ Medium       │ A[MC, KC]        │ Inside jr loop       │<br> * │             │              │                  │ Reuse: NC/NR times   │<br> * ├─────────────┼──────────────┼──────────────────┼──────────────────────┤<br> * │ L3 (18MB)   │ Largest/     │ B[NC, KC]        │ Inside i loop        │<br> * │             │ Slowest      │                  │ Reuse: M/MC times    │<br> * └─────────────┴──────────────┴──────────────────┴──────────────────────┘<br> */<br></code></pre></td></tr></table></figure><h2 id="5-2-分块参数计算"><a href="#5-2-分块参数计算" class="headerlink" title="5.2 分块参数计算"></a>5.2 分块参数计算</h2><p>根据缓存大小反推分块参数：</p><p>约束条件：</p><ul><li>KC × NR × 4 ≤ L1_size          (B panel 放 L1)</li><li>MC × KC × 4 ≤ L2_size          (A block 放 L2)  </li><li>NC × KC × 4 ≤ L3_size          (B block 放 L3)</li></ul><p>对于配置 MR&#x3D;14, NR&#x3D;32：</p><ul><li>KC &#x3D; 384（保证 B panel 适合 L1）</li><li>MC &#x3D; 840（保证 A block 适合 L2）</li><li>NC &#x3D; 1024（保证 B block 适合 L3）</li></ul><h3 id="claude-insight"><a href="#claude-insight" class="headerlink" title="claude insight"></a>claude insight</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">/*<br> * ============================================================<br> * [ L1 Cache Budget Analysis ] Total: 48 KB<br> * ============================================================<br> *<br> * 1. Resident Block (B Panel):<br> * -------------------------<br> * Dim : NR(32) x KC(384)<br> * Size: 48 KB<br> * Note: TAKES 100% ROOM. No space left for A.<br> *<br> * 2. Streaming Block (A Panel):<br> * --------------------------<br> * Dim : MR(14) x KC(384)<br> * Size: 21 KB<br> * Note: CACHE SPILL. Performance penalty.<br> *<br> * ------------------------------------------------------------<br> * TOTAL REQUIRED: ~69 KB  ( &gt; 48 KB Limit )<br> * ACTION: Reduce KC block size.<br> * ============================================================<br> */<br></code></pre></td></tr></table></figure><p>claude 认为前面的约束条件中：</p><ul><li>KC × NR × 4 ≤ L1_size &#x2F; 2  (B panel 放 L1)</li></ul><p>是比较好的工程实践，原因如下：</p><ol><li>A 的访问：虽然 A 主要驻留 L2，但当前 micro-kernel 正在使用的 A[MR, KC] 也会进入 L1</li><li>避免 cache 颠簸：如果 B panel 占满 L1，A 的访问会把 B 换出，然后 B 又把 A 换出，反复颠簸</li><li>安全余量：L1 cache 是组相联的，不是所有空间都能被有效利用，预留一半是工程经验值</li></ol><div class="note note-info">            <p><strong>简单来说：</strong> 除以 2 是为了给 A 和其他数据留出空间，避免 B 和 A 在 L1 中互相驱逐。</p>           </div><h2 id="5-3-循环嵌套结构"><a href="#5-3-循环嵌套结构" class="headerlink" title="5.3 循环嵌套结构"></a>5.3 循环嵌套结构</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// Optimization: Cache Blocking + Packing + Register Blocking (AVX-512)</span><br><span class="hljs-comment">// C = A * B^T + C</span><br><span class="hljs-comment">// Layout: C[M, N], A[M, K], B[N, K] (Row-Major)</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">matmul_v4_cache_opt</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *A, <span class="hljs-type">const</span> <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">size_t</span> M, <span class="hljs-type">size_t</span> N, <span class="hljs-type">size_t</span> K)</span> </span>&#123;<br><br>    <span class="hljs-comment">// 1. Loop over N (L3 Cache Blocking for B)</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> j = <span class="hljs-number">0</span>; j &lt; N; j += NC) &#123;<br>        <span class="hljs-type">int</span> nc = <span class="hljs-built_in">MIN</span>(N - j, NC);<br><br>        <span class="hljs-comment">// 2. Loop over K (Reduction Dimension)</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> p = <span class="hljs-number">0</span>; p &lt; K; p += KC) &#123;<br>            <span class="hljs-type">int</span> kc = <span class="hljs-built_in">MIN</span>(K - p, KC);<br><br>            <span class="hljs-comment">// Pack Block B into contiguous memory (L2 Cache friendly)</span><br>            <span class="hljs-built_in">pack_blockB</span>(&amp;B[j * K + p], blockB_packed, nc, kc, K);<br><br>            <span class="hljs-comment">// 3. Loop over M (L2 Cache Blocking for A)</span><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; M; i += MC) &#123;<br>                <span class="hljs-type">int</span> mc = <span class="hljs-built_in">MIN</span>(M - i, MC);<br><br>                <span class="hljs-comment">// Pack Block A into contiguous memory</span><br>                <span class="hljs-built_in">pack_blockA</span>(&amp;A[i * K + p], blockA_packed, mc, kc, K);<br><br>                <span class="hljs-comment">// 4. Micro-Kernel Loops (Register Blocking)</span><br>                <span class="hljs-comment">// Iterate over the packed blocks</span><br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> jr = <span class="hljs-number">0</span>; jr &lt; nc; jr += NR) &#123;<br>                    <span class="hljs-type">int</span> nr = <span class="hljs-built_in">MIN</span>(NR, nc - jr);<br><br>                    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> ir = <span class="hljs-number">0</span>; ir &lt; mc; ir += MR) &#123;<br>                        <span class="hljs-type">int</span> mr = <span class="hljs-built_in">MIN</span>(MR, mc - ir);<br><br>                        <span class="hljs-comment">// Compute 14x32 block</span><br>                        <span class="hljs-built_in">micro_kernel</span>(<br>                            &amp;blockA_packed[ir * kc], <span class="hljs-comment">// A ptr moves by KC * MR elements</span><br>                            &amp;blockB_packed[jr * kc], <span class="hljs-comment">// B ptr moves by KC * NR elements</span><br>                            &amp;C[(i + ir) * N + (j + jr)],<br>                            mr, nr, kc, N);<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="5-4-数据复用分析"><a href="#5-4-数据复用分析" class="headerlink" title="5.4 数据复用分析"></a>5.4 数据复用分析</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">B[NC, KC] 的复用：<br>─────────────────<br>- Pack 一次<br>- 在 Loop 3（i 循环）中被复用 M/MC 次<br>- 每个 micro-kernel 再复用 KC 次<br><br>A[MC, KC] 的复用：<br>─────────────────<br>- Pack 一次  <br>- 在 Loop 4（jr 循环）中被复用 NC/NR 次<br>- 每个 micro-kernel 再复用 KC 次<br><br>总复用率 = O(MNK) 计算量 / O(MK + NK) 访存量 ≈ O(N)<br></code></pre></td></tr></table></figure><h1 id="第六部分：数据打包（Packing）"><a href="#第六部分：数据打包（Packing）" class="headerlink" title="第六部分：数据打包（Packing）"></a>第六部分：数据打包（Packing）</h1><h2 id="6-1-为什么需要-Pack？"><a href="#6-1-为什么需要-Pack？" class="headerlink" title="6.1 为什么需要 Pack？"></a>6.1 为什么需要 Pack？</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">原始 B[N, K] 按行存储：<br><br>内存地址: [B00 B01 B02 ... B0,K-1] [B10 B11 B12 ... B1,K-1] ...<br><br>micro-kernel 需要读取 B[:, k]（一列）：<br>  B[0,k], B[1,k], B[2,k], ..., B[31,k]<br>  地址跨度 = K × sizeof(float)<br><br>问题：<br>  • 如果 K=4096，每次跨越 16KB！<br>  • Cache line 利用率 = 1/K ≈ 0<br>  • 预取器无法预测访问模式<br></code></pre></td></tr></table></figure><h2 id="6-2-Pack-后的内存布局"><a href="#6-2-Pack-后的内存布局" class="headerlink" title="6.2 Pack 后的内存布局"></a>6.2 Pack 后的内存布局</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">Pack B 后的布局（按 k 优先）：<br><br>┌─────────────────────────────────────────────────────────────┐<br>│ B[0,0] B[1,0] B[2,0] ... B[31,0] │ B[0,1] B[1,1] ... B[31,1]│ ...<br>└─────────────────────────────────────────────────────────────┘<br>  └────── k=0 的 32 个元素 ──────┘   └────── k=1 的 32 个 ────┘<br><br>micro-kernel 访问 B[:, k]：<br>  连续读取 32 个 float = 128 bytes = 2 个 cache line ✓<br>  预取器可以完美预测 ✓<br></code></pre></td></tr></table></figure><h2 id="6-3-Pack-实现"><a href="#6-3-Pack-实现" class="headerlink" title="6.3 Pack 实现"></a>6.3 Pack 实现</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @brief Packs a panel of Matrix A into contiguous memory.</span><br><span class="hljs-comment"> * Layout: [KC, MR] (Row-Major within the block).</span><br><span class="hljs-comment"> * Goal:   Optimized for broadcasting A elements in the FMA loop.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">pack_panelA</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *packed_ptr, <span class="hljs-type">int</span> mr, <span class="hljs-type">int</span> kc, <span class="hljs-type">int</span> K_stride)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; kc; ++k) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; mr; ++i) &#123;<br>            *packed_ptr++ = A[i * K_stride + k];<br>        &#125;<br>        <span class="hljs-comment">// Zero-padding if mr &lt; MR</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = mr; i &lt; MR; ++i) &#123;<br>            *packed_ptr++ = <span class="hljs-number">0.0f</span>;<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @brief Block-level wrapper for packing A.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">pack_blockA</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *packed_buffer, <span class="hljs-type">int</span> mc, <span class="hljs-type">int</span> kc, <span class="hljs-type">int</span> K_stride)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; mc; i += MR) &#123;<br>        <span class="hljs-type">int</span> mr = <span class="hljs-built_in">MIN</span>(MR, mc - i);<br>        <span class="hljs-built_in">pack_panelA</span>(&amp;A[i * K_stride], &amp;packed_buffer[i * kc], mr, kc, K_stride);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @brief Packs a panel of Matrix B into contiguous memory.</span><br><span class="hljs-comment"> * Layout: [KC, NR] (Row-Major within the block).</span><br><span class="hljs-comment"> * Goal:   Optimized for sequential vector loads (ZMM) in the FMA loop.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">pack_panelB</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *packed_ptr, <span class="hljs-type">int</span> nr, <span class="hljs-type">int</span> kc, <span class="hljs-type">int</span> K_stride)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = <span class="hljs-number">0</span>; k &lt; kc; ++k) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; nr; ++j) &#123;<br>            *packed_ptr++ = B[j * K_stride + k];<br>        &#125;<br>        <span class="hljs-comment">// Zero-padding if nr &lt; NR</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = nr; j &lt; NR; ++j) &#123;<br>            *packed_ptr++ = <span class="hljs-number">0.0f</span>;<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @brief Block-level wrapper for packing B.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">pack_blockB</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *packed_buffer, <span class="hljs-type">int</span> nc, <span class="hljs-type">int</span> kc, <span class="hljs-type">int</span> K_stride)</span> </span>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; nc; j += NR) &#123;<br>        <span class="hljs-type">int</span> nr = <span class="hljs-built_in">MIN</span>(NR, nc - j);<br>        <span class="hljs-built_in">pack_panelB</span>(&amp;B[j * K_stride], &amp;packed_buffer[j * kc], nr, kc, K_stride);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="6-4-Pack-开销分析"><a href="#6-4-Pack-开销分析" class="headerlink" title="6.4 Pack 开销分析"></a>6.4 Pack 开销分析</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">Pack 开销 = O(MK + NK)<br>计算开销 = O(MNK)<br><br>比例 = (MK + NK) / (MNK) = 1/N + 1/M<br><br>当 M = N = K = 4096 时：<br>  Pack 占比 ≈ 2/4096 ≈ 0.05%<br><br>结论：对于大矩阵，Pack 开销可以忽略不计<br></code></pre></td></tr></table></figure><h1 id="第七部分：指令级并行与循环展开"><a href="#第七部分：指令级并行与循环展开" class="headerlink" title="第七部分：指令级并行与循环展开"></a>第七部分：指令级并行与循环展开</h1><h2 id="7-1-FMA-指令的流水线特性"><a href="#7-1-FMA-指令的流水线特性" class="headerlink" title="7.1 FMA 指令的流水线特性"></a>7.1 FMA 指令的流水线特性</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">Intel Skylake-X / Ice Lake 的 FMA 特性：<br>  • Latency（延迟）: 4 cycles<br>  • Throughput（吞吐）: 2/cycle（Port 0 和 Port 1）<br><br>要打满吞吐，需要足够的独立指令填充流水线：<br>  所需独立 FMA 数 = Latency × Throughput = 4 × 2 = 8<br></code></pre></td></tr></table></figure><h2 id="7-2-FMA-循环展开"><a href="#7-2-FMA-循环展开" class="headerlink" title="7.2 FMA 循环展开"></a>7.2 FMA 循环展开</h2><ol><li>消除循环控制开销</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 未展开：每次迭代有额外开销</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">14</span>; ++i) &#123;<br>    C[i] = <span class="hljs-built_in">FMA</span>(A[i], B, C[i]);<br>    <span class="hljs-comment">// 隐含：i++, cmp i &lt; 14, jmp</span><br>&#125;<br><br><span class="hljs-comment">// 展开后：纯计算，无控制指令</span><br>C[<span class="hljs-number">0</span>] = <span class="hljs-built_in">FMA</span>(A[<span class="hljs-number">0</span>], B, C[<span class="hljs-number">0</span>]);<br>C[<span class="hljs-number">1</span>] = <span class="hljs-built_in">FMA</span>(A[<span class="hljs-number">1</span>], B, C[<span class="hljs-number">1</span>]);<br>...<br></code></pre></td></tr></table></figure><ol start="2"><li>帮助编译器优化寄存器分配</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 未展开：编译器可能通过内存/索引访问 C[i]</span><br>C[i] = ...  <span class="hljs-comment">// i 是变量，可能无法确定分配哪个寄存器</span><br><br><span class="hljs-comment">// 展开后：编译器明确知道每个累加器，直接分配到固定寄存器</span><br>C_accum_0 = ...  <span class="hljs-comment">// → ZMM0</span><br>C_accum_1 = ...  <span class="hljs-comment">// → ZMM1</span><br>...<br></code></pre></td></tr></table></figure><ol start="3"><li>增加指令级并行的可见性<br>虽然 C[0]~C[13] 本身独立，但展开后 CPU 的调度器能更容易地同时发射多条独立指令，而不需要动态分析循环迭代间的独立性。</li></ol><h1 id="第八部分：多线程并行化"><a href="#第八部分：多线程并行化" class="headerlink" title="第八部分：多线程并行化"></a>第八部分：多线程并行化</h1><h2 id="8-1-并行策略"><a href="#8-1-并行策略" class="headerlink" title="8.1 并行策略"></a>8.1 并行策略</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">constexpr</span> <span class="hljs-type">int</span> NTHREADS = <span class="hljs-number">24</span>;<br><br><span class="hljs-comment">// Helper to stringify the thread count for the pragma</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> PRAGMA_STR(x) <span class="hljs-keyword">_Pragma</span>(#x)</span><br><br><span class="hljs-comment">// We strictly enforce num_threads to match our blocking logic.</span><br><span class="hljs-comment">// Usage: PARALLEL_FOR_LOOP</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> PARALLEL_FOR_LOOP PRAGMA_STR(omp parallel for num_threads(NTHREADS))</span><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @brief Packs a block of Matrix A in PARALLEL.</span><br><span class="hljs-comment"> * Splitting the packing workload speeds up the pre-processing phase.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">pack_blockA</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *A, <span class="hljs-type">float</span> *packed_buffer, <span class="hljs-type">int</span> mc, <span class="hljs-type">int</span> kc, <span class="hljs-type">int</span> K_stride)</span> </span>&#123;<br>    <span class="hljs-function">PARALLEL_FOR_LOOP</span><br><span class="hljs-function">    <span class="hljs-title">for</span> <span class="hljs-params">(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; mc; i += MR)</span> </span>&#123;<br>        <span class="hljs-type">int</span> mr = <span class="hljs-built_in">MIN</span>(MR, mc - i);<br>        <span class="hljs-comment">// Each thread packs a distinct panel, no data race on packed_buffer.</span><br>        <span class="hljs-built_in">pack_panelA</span>(&amp;A[i * K_stride], &amp;packed_buffer[i * kc], mr, kc, K_stride);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * @brief Packs a block of Matrix B in PARALLEL.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title">pack_blockB</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *packed_buffer, <span class="hljs-type">int</span> nc, <span class="hljs-type">int</span> kc, <span class="hljs-type">int</span> K_stride)</span> </span>&#123;<br>    <span class="hljs-function">PARALLEL_FOR_LOOP</span><br><span class="hljs-function">    <span class="hljs-title">for</span> <span class="hljs-params">(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; nc; j += NR)</span> </span>&#123;<br>        <span class="hljs-type">int</span> nr = <span class="hljs-built_in">MIN</span>(NR, nc - j);<br>        <span class="hljs-built_in">pack_panelB</span>(&amp;B[j * K_stride], &amp;packed_buffer[j * kc], nr, kc, K_stride);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// Optimization: Cache Blocking + Packing + Register Blocking + OpenMP Parallelism</span><br><span class="hljs-comment">// C = A * B^T + C</span><br><span class="hljs-comment">// Layout: Row-Major</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">matmul_v5_parallel</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">float</span> *A, <span class="hljs-type">const</span> <span class="hljs-type">float</span> *B, <span class="hljs-type">float</span> *C, <span class="hljs-type">size_t</span> M, <span class="hljs-type">size_t</span> N, <span class="hljs-type">size_t</span> K)</span> </span>&#123;<br><br>    <span class="hljs-comment">// 1. Loop over N (L3 Cache Blocking for B)</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> j = <span class="hljs-number">0</span>; j &lt; N; j += NC) &#123;<br>        <span class="hljs-type">int</span> nc = <span class="hljs-built_in">MIN</span>(N - j, NC);<br><br>        <span class="hljs-comment">// 2. Loop over K (Reduction Dimension)</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> p = <span class="hljs-number">0</span>; p &lt; K; p += KC) &#123;<br>            <span class="hljs-type">int</span> kc = <span class="hljs-built_in">MIN</span>(K - p, KC);<br><br>            <span class="hljs-comment">// Pack B in PARALLEL</span><br>            <span class="hljs-comment">// Threads work on disjoint parts of blockB_packed -&gt; Thread Safe.</span><br>            <span class="hljs-built_in">pack_blockB</span>(&amp;B[j * K + p], blockB_packed, nc, kc, K);<br><br>            <span class="hljs-comment">// 3. Loop over M (L2 Cache Blocking for A)</span><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">size_t</span> i = <span class="hljs-number">0</span>; i &lt; M; i += MC) &#123;<br>                <span class="hljs-type">int</span> mc = <span class="hljs-built_in">MIN</span>(M - i, MC);<br><br>                <span class="hljs-comment">// Pack A in PARALLEL</span><br>                <span class="hljs-comment">// Threads work on disjoint parts of blockA_packed -&gt; Thread Safe.</span><br>                <span class="hljs-built_in">pack_blockA</span>(&amp;A[i * K + p], blockA_packed, mc, kc, K);<br><br>                <span class="hljs-comment">// 4. Parallel Compute Loop</span><br>                <span class="hljs-comment">// Threads divide the columns (jr) of the current block.</span><br>                <span class="hljs-comment">// All threads read from the shared blockA_packed and blockB_packed (Read-Only).</span><br>                <span class="hljs-comment">// Threads write to disjoint parts of C (Write-Safe).</span><br>                <span class="hljs-function">PARALLEL_FOR_LOOP</span><br><span class="hljs-function">                <span class="hljs-title">for</span> <span class="hljs-params">(<span class="hljs-type">int</span> jr = <span class="hljs-number">0</span>; jr &lt; nc; jr += NR)</span> </span>&#123;<br>                    <span class="hljs-type">int</span> nr = <span class="hljs-built_in">MIN</span>(NR, nc - jr);<br><br>                    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> ir = <span class="hljs-number">0</span>; ir &lt; mc; ir += MR) &#123;<br>                        <span class="hljs-type">int</span> mr = <span class="hljs-built_in">MIN</span>(MR, mc - ir);<br><br>                        <span class="hljs-built_in">micro_kernel</span>(<br>                            &amp;blockA_packed[ir * kc],<br>                            &amp;blockB_packed[jr * kc],<br>                            &amp;C[(i + ir) * N + (j + jr)],<br>                            mr, nr, kc, N);<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="8-2-多核性能结果"><a href="#8-2-多核性能结果" class="headerlink" title="8.2 多核性能结果"></a>8.2 多核性能结果</h2><p>测试配置：M &#x3D; N &#x3D; K &#x3D; 4096，24 线程</p><table><thead><tr><th>Kernel</th><th>Peak GFLOPS</th><th>Avg GFLOPS</th></tr></thead><tbody><tr><td><code>core_v5_parallel</code></td><td>2010.61</td><td>1909.40</td></tr><tr><td><code>blas_row_AB^T</code></td><td>1914.91</td><td>1796.69</td></tr></tbody></table><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://www.intel.com/content/www/us/en/products/sku/215277/intel-xeon-silver-4310-processor-18m-cache-2-10-ghz/specifications.html">https://www.intel.com/content/www/us/en/products/sku/215277/intel-xeon-silver-4310-processor-18m-cache-2-10-ghz/specifications.html</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://zhuanlan.zhihu.com/p/34204282">Roofline Model与深度学习模型的性能分析</a><a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://mp.weixin.qq.com/s/hARNYew5nluJB_bk9_1qZA">现代多核处理器上的高级矩阵乘法优化</a><a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>高性能计算</category>
      
      <category>CPU并行编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OpenMP</tag>
      
      <tag>OpenBLAS</tag>
      
      <tag>HPC</tag>
      
      <tag>SIMD</tag>
      
      <tag>矩阵乘法</tag>
      
      <tag>性能优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OpenMP / OpenBLAS 线程管理策略总结</title>
    <link href="/hpc/cpu/omp-blas-thread-management.html"/>
    <url>/hpc/cpu/omp-blas-thread-management.html</url>
    
    <content type="html"><![CDATA[<p>本文总结了 OpenMP (libgomp) 和 OpenBLAS 两个库的线程管理机制，包括线程池创建、生命周期、环境变量控制以及它们之间的交互关系。</p><div class="note note-success">            <p>代码库和测试详见：<a href="https://github.com/tianyuxbear/omp-blas-thread-lab">https://github.com/tianyuxbear/omp-blas-thread-lab</a></p>           </div><h1 id="1-核心概念区分"><a href="#1-核心概念区分" class="headerlink" title="1. 核心概念区分"></a>1. 核心概念区分</h1><h2 id="1-1-物理核心-vs-逻辑核心"><a href="#1-1-物理核心-vs-逻辑核心" class="headerlink" title="1.1 物理核心 vs 逻辑核心"></a>1.1 物理核心 vs 逻辑核心</h2><ul><li>物理核心 (Physical Cores): 实际的 CPU 计算单元</li><li>逻辑核心 (Logical Cores):  操作系统看到的核心数 </li><li>启用超线程 (Hyper-Threading) 时:<ul><li>逻辑核心 &#x3D; 物理核心 × 2</li><li>例: 24 物理核心 + HT &#x279C; 48 逻辑核心</li></ul></li></ul><p><strong>对 GEMM 等计算密集型任务的影响：</strong></p><ul><li>超线程的两个逻辑核心共享同一物理核心的 L1&#x2F;L2 Cache 和 FMA 单元</li><li>使用 48 线程（逻辑核心数）可能比 24 线程（物理核心数）更慢</li><li><strong>建议：</strong> GEMM 类任务使用物理核心数</li></ul><h2 id="1-2-并行-vs-并发"><a href="#1-2-并行-vs-并发" class="headerlink" title="1.2 并行 vs 并发"></a>1.2 并行 vs 并发</h2><p><strong>线程数 ≤ 核心数:  并行 (Parallel)</strong></p><ul><li>每个线程独占一个核心</li><li>真正的同时执行</li></ul><p><strong>线程数 &gt; 核心数:  并发 (Concurrent)</strong></p><ul><li>线程共享核心，时间片轮转</li><li>有上下文切换开销</li><li>性能可能下降</li></ul><h1 id="2-OpenMP-libgomp-线程管理"><a href="#2-OpenMP-libgomp-线程管理" class="headerlink" title="2. OpenMP (libgomp) 线程管理"></a>2. OpenMP (libgomp) 线程管理</h1><h2 id="2-1-线程模型：按需创建-销毁"><a href="#2-1-线程模型：按需创建-销毁" class="headerlink" title="2.1 线程模型：按需创建&#x2F;销毁"></a>2.1 线程模型：按需创建&#x2F;销毁</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">【OpenMP 线程模型：动态 Fork-Join 视图】<br><br>时间轴 (↓)<br>  │<br>  │ [ 串行区 ] (只有主线程)<br>  │ 主线程 T0 🟢<br>  │<br>  ▼<br>┌────────────────── FORK (分叉) ──────────────────┐<br>│指令: #pragma omp parallel num_threads(24)       │<br>│动作: 主线程创建/唤醒 23 个工作线程              │<br>└─────────────────────────────────────────────────┘<br>  │<br>  │ 并行区 1 (共24线程)<br>  ├─── T0 🟢 (主) ──→ [ 执行任务 ] ──┐<br>  ├─── T1 🟠 (工) ──→ [ 执行任务 ] ──┤<br>  ├─── T2 🟠 (工) ──→ [ 执行任务 ] ──┤<br>  │    . . . (省略 T3-T22) . . .     │<br>  └─── T23🟠 (工) ──→ [ 执行任务 ] ──┘<br>  │<br>  ▼<br>┌────────────────── JOIN (合并) ──────────────────┐<br>│动作: 遇到隐式屏障，等待所有线程完成。           │<br>│      工作线程 T1-T23 被销毁 (概念上)。          │<br>└─────────────────────────────────────────────────┘<br>  │<br>  │ [ 串行区 ] (只有主线程)<br>  │ 主线程 T0 🟢<br>  │<br>  ▼<br>┌────────────────── FORK (分叉) ──────────────────┐<br>│指令: #pragma omp parallel num_threads(4)        │<br>│动作: 主线程创建/唤醒 3 个工作线程               │<br>└─────────────────────────────────────────────────┘<br>  │<br>  │ 并行区 2 (共4线程 - 宽度变窄)<br>  ├─── T0 🟢 (主) ──→ [ 执行任务 ] ──┐<br>  ├─── T1 🟠 (工) ──→ [ 执行任务 ] ──┤<br>  ├─── T2 🟠 (工) ──→ [ 执行任务 ] ──┤<br>  └─── T3 🟠 (工) ──→ [ 执行任务 ] ──┘<br>  │<br>  ▼<br>┌────────────────── JOIN (合并) ──────────────────┐<br>│动作: 屏障同步。工作线程 T1-T3 被销毁。          │<br>└─────────────────────────────────────────────────┘<br>  │<br>  │ [ 串行区 ] (只有主线程)<br>  │ 主线程 T0 🟢<br>  │<br>  ▼<br>┌────────────────── FORK (分叉) ──────────────────┐<br>│指令: #pragma omp parallel num_threads(48)       │<br>│动作: 主线程创建/唤醒 47 个工作线程              │<br>└─────────────────────────────────────────────────┘<br>  │<br>  │ 并行区 3 (共48线程 - 宽度显著增加)<br>  ├─── T0 🟢 (主) ───→ [ 执行任务 ] ──┐<br>  │                                      │<br>  ├─── [ 密集的工作线程组 T1 - T47 ] ────┤ 🟠 (×47)<br>  │    (此处代表大量并行执行的线程)      │<br>  │                                      │<br>  └─── (示意图宽度不足以全画出) ─────────┘<br>  │<br>  ▼<br>┌────────────────── JOIN (合并) ──────────────────┐<br>│动作: 屏障同步。工作线程 T1-T47 被销毁。         │<br>└─────────────────────────────────────────────────┘<br>  │<br>  │ [ 串行区 ] (只有主线程)<br>  │ 主线程 T0 🟢<br>  │<br>  ▼<br>[ 程序结束 ]<br><br>图例:<br>🟢 = 主线程 (Master Thread), 在整个程序生命周期内存在。<br>🟠 = 工作线程 (Worker Threads), 仅在并行区内存在 (逻辑上)。<br></code></pre></td></tr></table></figure><blockquote><p>注：libgomp 的实际实现可能有线程缓存优化，但观测到的行为是按需变化</p></blockquote><h2 id="2-2-关键特性"><a href="#2-2-关键特性" class="headerlink" title="2.2 关键特性"></a>2.2 关键特性</h2><table><thead><tr><th align="left">特性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">初始化时机</td><td align="left">首次进入 parallel region</td></tr><tr><td align="left">线程数</td><td align="left">每个 region 可以不同</td></tr><tr><td align="left">生命周期</td><td align="left">region 结束后销毁（或缓存复用）</td></tr><tr><td align="left">默认线程数</td><td align="left"><code>omp_get_max_threads()</code></td></tr></tbody></table><h2 id="2-3-API-函数"><a href="#2-3-API-函数" class="headerlink" title="2.3 API 函数"></a>2.3 API 函数</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 获取当前默认线程数（可配置值，不是硬件限制）</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">omp_get_max_threads</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>;<br><br><span class="hljs-comment">// 设置后续 parallel region 的默认线程数</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">omp_set_num_threads</span><span class="hljs-params">(<span class="hljs-type">int</span> num)</span></span>;<br><br><span class="hljs-comment">// 获取系统逻辑核心数（硬件信息，固定值）</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">omp_get_num_procs</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>;<br><br><span class="hljs-comment">// 在 parallel region 内：获取当前 region 的实际线程数</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">omp_get_num_threads</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>;<br><br><span class="hljs-comment">// 获取绝对上限（通常是一个很大的数）</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">omp_get_thread_limit</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>;<br></code></pre></td></tr></table></figure><h2 id="2-4-线程数控制优先级"><a href="#2-4-线程数控制优先级" class="headerlink" title="2.4 线程数控制优先级"></a>2.4 线程数控制优先级</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">┌──────────────────────────────────────────────────────────────<br>│ OpenMP 线程设置优先级（从高到低 ⬇️）<br>├──────────────────────────────────────────────────────────────<br>│ 🥇 1. #pragma omp parallel num_threads(N)<br>│      ├── 最高优先级，覆盖一切<br>│      ├── 可以超过 omp_get_max_threads()<br>│      └── 可以超过逻辑核心数（变成并发）<br>│<br>│ 🥈 2. omp_set_num_threads(N)<br>│      ├── 运行时修改默认值<br>│      └── 影响后续没有 num_threads 子句的 region<br>│<br>│ 🥉 3. OMP_NUM_THREADS 环境变量<br>│      ├── 程序启动时的初始默认值<br>│      └── 设置 omp_get_max_threads() 的初始值<br>│<br>│ 🔹 4. 实现默认值 (System Default)<br>│      └── 通常等于逻辑核心数<br>└──────────────────────────────────────────────────────────────<br></code></pre></td></tr></table></figure><h2 id="2-5-OMP-NUM-THREADS-不是硬上限"><a href="#2-5-OMP-NUM-THREADS-不是硬上限" class="headerlink" title="2.5 OMP_NUM_THREADS 不是硬上限"></a>2.5 OMP_NUM_THREADS 不是硬上限</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 假设 OMP_NUM_THREADS=8</span><br><br><span class="hljs-built_in">omp_get_max_threads</span>();  <span class="hljs-comment">// → 8 (默认值)</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp parallel  <span class="hljs-comment">// 不指定 num_threads</span></span><br>&#123;<br>    <span class="hljs-built_in">omp_get_num_threads</span>();  <span class="hljs-comment">// → 8 (使用默认值)</span><br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp parallel num_threads(24)  <span class="hljs-comment">// 显式指定</span></span><br>&#123;<br>    <span class="hljs-built_in">omp_get_num_threads</span>();  <span class="hljs-comment">// → 24 (可以超过默认值!)</span><br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> omp parallel num_threads(64)  <span class="hljs-comment">// 超过逻辑核心数</span></span><br>&#123;<br>    <span class="hljs-built_in">omp_get_num_threads</span>();  <span class="hljs-comment">// → 64 (可以! 但是是并发不是并行)</span><br>&#125;<br></code></pre></td></tr></table></figure><h1 id="3-OpenBLAS-线程管理"><a href="#3-OpenBLAS-线程管理" class="headerlink" title="3. OpenBLAS 线程管理"></a>3. OpenBLAS 线程管理</h1><h2 id="3-1-线程池模型：固定池"><a href="#3-1-线程池模型：固定池" class="headerlink" title="3.1 线程池模型：固定池"></a>3.1 线程池模型：固定池</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">┌──────────────────────────────────────────────────────────────<br>│ 🚀 OpenBLAS 线程生命周期 (Thread Lifecycle)<br>├──────────────────────────────────────────────────────────────<br>│<br>│ ▶️ 程序启动 (Program Start)<br>│      │<br>│      ▼<br>│ 📦 动态链接器加载 libopenblas.so<br>│      │<br>│      ▼<br>│ ╔══ ⚙️ 初始化阶段 (Constructor Phase) ════════════════════<br>│ ║    (在 main() 之前执行 __attribute__((constructor)))<br>│ ║<br>│ ║  1️⃣ 📖 读取环境变量 OPENBLAS_NUM_THREADS<br>│ ║  2️⃣ 🏊 创建初始大小的线程池 (Thread Pool Created)<br>│ ║  3️⃣ 📈 关键特性: 线程池可扩展，但不再缩小 (Grow Only)<br>│ ╚══════════════════════════════════════════════════════════<br>│      │<br>│      ▼<br>│ 🧊 C++ 静态初始化 (Static Initializers)<br>│      *(注: 此时 OpenBLAS 线程池已存在并就绪)*<br>│      │<br>│      ▼<br>│ 🏁 main() 函数开始执行<br>│<br>└──────────────────────────────────────────────────────────────<br></code></pre></td></tr></table></figure><h2 id="3-2-关键特性"><a href="#3-2-关键特性" class="headerlink" title="3.2 关键特性"></a>3.2 关键特性</h2><table><thead><tr><th align="left">特性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">初始化时机</td><td align="left">库加载时（constructor），在 <code>main()</code> 之前</td></tr><tr><td align="left">触发条件</td><td align="left">代码中引用了任何 OpenBLAS 符号（延迟绑定）</td></tr><tr><td align="left">初始池大小</td><td align="left">由 <code>OPENBLAS_NUM_THREADS</code> 环境变量决定（默认 &#x3D; 逻辑核心数）</td></tr><tr><td align="left">池大小变化</td><td align="left">只扩展，不缩小（类似 <code>std::vector</code> 的 capacity）</td></tr><tr><td align="left">生命周期</td><td align="left">程序结束时销毁</td></tr></tbody></table><h2 id="3-3-API-函数"><a href="#3-3-API-函数" class="headerlink" title="3.3 API 函数"></a>3.3 API 函数</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 获取当前&quot;使用&quot;的线程数（不是池大小）</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">openblas_get_num_threads</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>;<br><br><span class="hljs-comment">// 设置线程数：</span><br><span class="hljs-comment">//   N &gt; 当前池大小 → 扩展池</span><br><span class="hljs-comment">//   N &lt; 当前池大小 → 只改变使用数，池不缩小</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">openblas_set_num_threads</span><span class="hljs-params">(<span class="hljs-type">int</span> num)</span></span>;<br><br><span class="hljs-comment">// 获取系统逻辑核心数（硬件信息，固定值）</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">openblas_get_num_procs</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>;<br><br><span class="hljs-comment">// 获取编译配置信息</span><br><span class="hljs-function"><span class="hljs-type">char</span>* <span class="hljs-title">openblas_get_config</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span></span>;<br></code></pre></td></tr></table></figure><h2 id="3-4-线程池行为详解"><a href="#3-4-线程池行为详解" class="headerlink" title="3.4 线程池行为详解"></a>3.4 线程池行为详解</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">┌──────────────────────────────────────────────────────────────────<br>│ 🚀 OPENBLAS_NUM_THREADS=8 启动程序<br>├──────────────────────────────────────────────────────────────────<br>│ 🟩 初始状态:<br>│ 📦 线程池: [T0][T1]...[T7]  ← (共 8 个线程)<br>│ ⚙️ 使用数: 8<br>│<br>├──────────────────────────────────────────────────────────────────<br>│ ▶️ openblas_set_num_threads(24):  📈 请求数 &gt; 池大小 → 扩展！<br>│<br>│ 📦 线程池: [T0][T1]...[T7][T8]...[T23]  ← (扩展到 24 个)<br>│ ⚙️ 使用数: 24<br>│<br>├──────────────────────────────────────────────────────────────────<br>│ ▶️ openblas_set_num_threads(4):   📉 请求数 &lt; 池大小 → 不缩小！<br>│<br>│ 📦 线程池: [T0][T1][T2][T3][💤][💤]...[💤]  (共 24 个仍存活)<br>│            ↑   ↑   ↑   ↑    ↑<br>│           🔥 工作中...     🛌 睡眠中 (20 个)<br>│ ⚙️ 使用数: 4<br>│<br>├──────────────────────────────────────────────────────────────────<br>│ ▶️ openblas_set_num_threads(48):  📈 请求数 &gt; 池大小 → 再次扩展！<br>│<br>│ 📦 线程池: [T0][T1]...[T47]  ← (扩展到 48 个)<br>│ ⚙️ 使用数: 48<br>│<br>├──────────────────────────────────────────────────────────────────<br>│ ▶️ openblas_set_num_threads(4):   📉 请求数 &lt; 池大小 → 不缩小！<br>│<br>│ 📦 线程池: [T0][T1][T2][T3][💤]...[💤]  (共 48 个仍存活)<br>│            ↑   ↑   ↑   ↑    ↑<br>│           🔥 工作中...     🛌 睡眠中 (44 个)<br>│ ⚙️ 使用数: 4<br>│<br>└──────────────────────────────────────────────────────────────────<br></code></pre></td></tr></table></figure><p><strong>总结:</strong></p><ul><li><strong>OPENBLAS_NUM_THREADS</strong> 控制初始池大小</li><li><code>set_num_threads(N)</code> 当 N &gt; 池大小时，扩展池</li><li><code>set_num_threads(N)</code> 当 N &lt; 池大小时，只改变使用数</li><li>池只增不减，类似 <code>std::vector</code> 的 <code>capacity</code></li></ul><h2 id="3-5-环境变量"><a href="#3-5-环境变量" class="headerlink" title="3.5 环境变量"></a>3.5 环境变量</h2><table><thead><tr><th align="left">环境变量</th><th align="left">作用</th><th align="left">优先级</th></tr></thead><tbody><tr><td align="left"><code>OPENBLAS_NUM_THREADS</code></td><td align="left">控制初始线程池大小</td><td align="left">最高</td></tr><tr><td align="left"><code>GOTO_NUM_THREADS</code></td><td align="left">兼容旧版 GotoBLAS</td><td align="left">次之</td></tr><tr><td align="left"><code>OMP_NUM_THREADS</code></td><td align="left">Fallback（部分构建版本）</td><td align="left">较低</td></tr><tr><td align="left">（无）</td><td align="left">使用逻辑核心数</td><td align="left">默认</td></tr></tbody></table><p><strong>注意：</strong> 环境变量只影响初始池大小，运行时 <code>set_num_threads()</code> 可以扩展池。</p><h1 id="4-对比总结"><a href="#4-对比总结" class="headerlink" title="4. 对比总结"></a>4. 对比总结</h1><h2 id="4-1-核心差异"><a href="#4-1-核心差异" class="headerlink" title="4.1 核心差异"></a>4.1 核心差异</h2><table><thead><tr><th align="left">维度</th><th align="left">OpenMP（libgomp）</th><th align="left">OpenBLAS</th></tr></thead><tbody><tr><td align="left">线程模型</td><td align="left">按需创建 &#x2F; 销毁</td><td align="left">可扩展池（只增不减）</td></tr><tr><td align="left">初始化时机</td><td align="left">首次 <code>parallel region</code></td><td align="left">库加载时（<code>main</code> 之前）</td></tr><tr><td align="left">池大小可变</td><td align="left">✅ 每次 region 可不同</td><td align="left">✅ 可扩展，❌ 不缩小</td></tr><tr><td align="left">“池大小” vs “使用数”</td><td align="left">统一</td><td align="left">分离（池 ≥ 使用数）</td></tr><tr><td align="left">空闲线程</td><td align="left">销毁</td><td align="left">睡眠，保持存活</td></tr><tr><td align="left">控制方式</td><td align="left">环境变量 + API + 子句</td><td align="left">环境变量 + <code>set_num_threads()</code></td></tr></tbody></table><h2 id="4-2-get-num-procs-的含义"><a href="#4-2-get-num-procs-的含义" class="headerlink" title="4.2 get_num_procs() 的含义"></a>4.2 <code>get_num_procs()</code> 的含义</h2><p>两个库的 <code>get_num_procs()</code> 含义相同：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">┌──────────────────────────────────────────────────────────────────<br>│ 🖥️  硬件核心数查询 (Hardware Query)<br>│     omp_get_num_procs() / openblas_get_num_procs()<br>├──────────────────────────────────────────────────────────────────<br>│<br>│ 🔢 核心功能:<br>│     └── 返回系统的逻辑核心数 (Logical Core Count)<br>│<br>│ ⚓️ 属性特征:<br>│     └── 属于硬件物理信息，是固定值 (Fixed Value)<br>│<br>│ 🛡️ 独立性:<br>│     └── 坚决不受 OMP_NUM_THREADS 等环境变量影响<br>│<br>│ 🔗 C++ 等价物:<br>│     └── ≈ std::thread::hardware_concurrency()<br>│<br>└──────────────────────────────────────────────────────────────────<br></code></pre></td></tr></table></figure><h1 id="5-环境变量交互"><a href="#5-环境变量交互" class="headerlink" title="5. 环境变量交互"></a>5. 环境变量交互</h1><h2 id="5-1-OpenBLAS-的-Fallback-机制"><a href="#5-1-OpenBLAS-的-Fallback-机制" class="headerlink" title="5.1 OpenBLAS 的 Fallback 机制"></a>5.1 OpenBLAS 的 Fallback 机制</h2><p>部分 OpenBLAS 构建版本在 <code>OPENBLAS_NUM_THREADS</code> 未设置时，会检查其他环境变量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">┌──────────────────────────────────────────────────────────────────<br>│ 📉 OpenBLAS 环境变量优先级 (Priority Chain)<br>│    (检查顺序：若上级未设置，则尝试下级)<br>├──────────────────────────────────────────────────────────────────<br>│<br>│ 👑 1. OPENBLAS_NUM_THREADS<br>│      │<br>│      ├── 最高优先级 (Highest Priority)<br>│      └── 专门针对 OpenBLAS 的设置<br>│      │<br>│      ▼<br>│ 🏛️ 2. GOTO_NUM_THREADS<br>│      │<br>│      ├── 历史兼容 (Legacy)<br>│      └── 兼容古老的 GotoBLAS 设置<br>│      │<br>│      ▼<br>│ 🤝 3. OMP_NUM_THREADS<br>│      │<br>│      ├── 通用回退 (Fallback)<br>│      └── 仅在编译时开启 OpenMP 支持时生效<br>│      │<br>│      ▼<br>│ 💻 4. 硬件逻辑核心数 (System Default)<br>│<br>│      ├── 兜底方案 (Baseline)<br>│      └── 如果以上都没设置，占满所有核心<br>│<br>└──────────────────────────────────────────────────────────────────<br></code></pre></td></tr></table></figure><h2 id="5-2-推荐做法"><a href="#5-2-推荐做法" class="headerlink" title="5.2 推荐做法"></a>5.2 推荐做法</h2><p>为避免意外行为，<strong>显式设置两个环境变量：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> OPENBLAS_NUM_THREADS=24<br><span class="hljs-built_in">export</span> OMP_NUM_THREADS=24<br>./program<br></code></pre></td></tr></table></figure><p>或单次运行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">OPENBLAS_NUM_THREADS=24 OMP_NUM_THREADS=24 ./program<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>高性能计算</category>
      
      <category>CPU并行编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OpenMP</tag>
      
      <tag>OpenBLAS</tag>
      
      <tag>HPC</tag>
      
      <tag>多线程</tag>
      
      <tag>并行计算</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于 Fluid 的高可用 Hexo 博客实践</title>
    <link href="/tutorials/hexo-fluid-guide.html"/>
    <url>/tutorials/hexo-fluid-guide.html</url>
    
    <content type="html"><![CDATA[<p>谨以此文纪念本站的诞生。<br>本站架构遵循<strong>计算与存储分离</strong>原则：基于 Hexo + Fluid 构建静态资源，源码托管于 GitHub，利用 Cloudflare Pages 与 Vercel 实现多线路全球分发。</p><h1 id="1-核心架构设计"><a href="#1-核心架构设计" class="headerlink" title="1. 核心架构设计"></a>1. 核心架构设计</h1><p>在开始动工前，明确本博客的工程拓扑：</p><ul><li><strong>核心仓库 (hexo-blog)</strong>: 仅包含站点配置 (<code>_config.yml</code>)、文章源码 (<code>source/</code>) 和依赖描述 (<code>package.json</code>)。</li><li><strong>主题管理 (Submodule)</strong>: 将 Fluid 主题作为子模块引入，确保主题更新与个性化配置解耦。</li><li><strong>部署策略 (Edge Computing)</strong>: 放弃传统的 GitHub Pages 直连，利用 Cloudflare 的 Anycast 网络实现毫秒级加载。</li></ul><h1 id="2-环境初始化"><a href="#2-环境初始化" class="headerlink" title="2. 环境初始化"></a>2. 环境初始化</h1><h2 id="基础依赖"><a href="#基础依赖" class="headerlink" title="基础依赖"></a>基础依赖</h2><p>请确保本地开发环境（Windows&#x2F;Mac&#x2F;Linux）已安装以下工具链：</p><ul><li><strong>Git</strong>: 版本控制核心。</li><li><strong>Node.js</strong>: 建议安装 LTS 版本 (推荐 v18+)。</li><li><strong>Hexo CLI</strong>:  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install -g hexo-cli<br></code></pre></td></tr></table></figure></li></ul><h2 id="仓库构建"><a href="#仓库构建" class="headerlink" title="仓库构建"></a>仓库构建</h2><p>本博客在本地建立项目 <code>Devhub/hexo-blog</code>。为了保持仓库整洁，不直接 clone 整个主题代码，而是采用初始化生成：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 初始化脚手架</span><br>hexo init hexo-blog<br><span class="hljs-built_in">cd</span> hexo-blog<br>npm install<br></code></pre></td></tr></table></figure><p>此时目录结构应清晰如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">.<br>├── _config.landscape.yml<br>├── _config.yml      # 站点全局配置<br>├── package.json     # 依赖管理<br>├── scaffolds        # 模板文件<br>│   ├── draft.md<br>│   ├── page.md<br>│   └── post.md<br>├── source           # 博客文章与自定义资源<br>│   └── _posts<br>│       └── hello-world.md<br>└── themes           # 主题目录<br></code></pre></td></tr></table></figure><div class="note note-info">            <p><strong>Git 策略提示</strong> 建议在 <code>.gitignore</code> 中排除 <code>node_modules</code> 和 <code>public</code> 目录。<code>package-lock.json</code> 建议保留以锁定依赖版本，确保多端构建一致性，但如果你追求极致的仓库轻量化，确保 <code>package.json</code> 版本号写死即可。</p>           </div><h1 id="3-主题管理：Fluid-的非侵入式集成"><a href="#3-主题管理：Fluid-的非侵入式集成" class="headerlink" title="3. 主题管理：Fluid 的非侵入式集成"></a>3. 主题管理：Fluid 的非侵入式集成</h1><p>为了解决“直接下载主题包难以更新”和“修改源码导致冲突”的痛点，我们采用 <strong>Git Submodule</strong> 方案。</p><h2 id="安装主题"><a href="#安装主题" class="headerlink" title="安装主题"></a>安装主题</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 移除默认主题（可选）</span><br><span class="hljs-built_in">rm</span> -rf themes/landscape<br><br><span class="hljs-comment"># 将 Fluid 挂载为子模块</span><br>git submodule add https://github.com/fluid-dev/hexo-theme-fluid.git themes/fluid<br></code></pre></td></tr></table></figure><h2 id="配置解耦-Shadow-Config"><a href="#配置解耦-Shadow-Config" class="headerlink" title="配置解耦 (Shadow Config)"></a>配置解耦 (Shadow Config)</h2><p>Fluid 支持“影子配置”模式。我们将主题的配置文件复制到根目录，并重命名为 <code>_config.fluid.yml</code>。Hexo 会优先读取此文件，从而覆盖 <code>themes/fluid/_config.yml</code> 中的默认值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cp</span> themes/fluid/_config.yml _config.fluid.yml<br></code></pre></td></tr></table></figure><p>之后所有对主题的修改（导航栏、颜色、功能开关）均在根目录的 <code>_config.fluid.yml</code> 中进行，<strong>永远不要修改 themes&#x2F;fluid 目录下的文件</strong>。</p><h2 id="站点基础配置"><a href="#站点基础配置" class="headerlink" title="站点基础配置"></a>站点基础配置</h2><p>修改 <code>hexo-blog/_config.yml</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Extensions</span><br><span class="hljs-attr">theme:</span> <span class="hljs-string">fluid</span><br><span class="hljs-attr">language:</span> <span class="hljs-string">zh-CN</span><br><span class="hljs-attr">timezone:</span> <span class="hljs-string">Asia/Shanghai</span><br><br><span class="hljs-comment"># URL (Cloudflare Pages 提供的域名或自定义域名)</span><br><span class="hljs-attr">url:</span> <span class="hljs-string">https://codebearjourney.top</span><br></code></pre></td></tr></table></figure><h1 id="4-深度定制与美化"><a href="#4-深度定制与美化" class="headerlink" title="4. 深度定制与美化"></a>4. 深度定制与美化</h1><h2 id="Mac-Style-代码高亮"><a href="#Mac-Style-代码高亮" class="headerlink" title="Mac-Style 代码高亮"></a>Mac-Style 代码高亮</h2><p>Fluid 支持自定义 CSS 注入。为了实现类似 Mac 窗口的圆角与红绿灯效果，我们采用<strong>外部注入</strong>的方式。</p><ol><li><strong>配置 Highlight.js：</strong> 在 <code>_config.fluid.yml</code> 中设置：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># 实现高亮的库，对应下面的设置</span><br><span class="hljs-comment"># Highlight library</span><br><span class="hljs-comment"># Options: highlightjs | prismjs</span><br><span class="hljs-attr">lib:</span> <span class="hljs-string">&quot;highlightjs&quot;</span><br><br><span class="hljs-attr">highlightjs:</span><br>  <span class="hljs-comment"># 在链接中挑选 style 填入</span><br>  <span class="hljs-comment"># Select a style in the link</span><br>  <span class="hljs-comment"># See: https://highlightjs.org/demo/</span><br>  <span class="hljs-attr">style:</span> <span class="hljs-string">&quot;atom-one-dark&quot;</span><br>  <span class="hljs-attr">style_dark:</span> <span class="hljs-string">&quot;atom-one-dark&quot;</span><br>  <span class="hljs-attr">bg_color:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><ol start="2"><li><strong>创建样式文件：</strong> 新建 <code>source/css/mac.styl</code>，粘贴以下内容：</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-class">.highlight</span><br>    <span class="hljs-attribute">background</span>: <span class="hljs-number">#282C34</span>   <span class="hljs-comment">/* Atom One Dark 背景色 */</span><br>    <span class="hljs-attribute">border-radius</span>: <span class="hljs-number">5px</span><br>    <span class="hljs-attribute">box-shadow</span>: <span class="hljs-number">0</span> <span class="hljs-number">10px</span> <span class="hljs-number">30px</span> <span class="hljs-number">0</span> <span class="hljs-built_in">rgba</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, .<span class="hljs-number">4</span>)<br>    <span class="hljs-attribute">padding-top</span>: <span class="hljs-number">30px</span><br><br>    <span class="hljs-selector-pseudo">&amp;::before</span><br>      <span class="hljs-attribute">content</span>: <span class="hljs-string">&#x27; &#x27;</span><br>      <span class="hljs-attribute">position</span>: absolute<br>      <span class="hljs-attribute">top</span>: <span class="hljs-number">15px</span><br>      <span class="hljs-attribute">left</span>: <span class="hljs-number">15px</span><br>      <span class="hljs-attribute">width</span>: <span class="hljs-number">12px</span><br>      <span class="hljs-attribute">height</span>: <span class="hljs-number">12px</span><br>      <span class="hljs-attribute">border-radius</span>: <span class="hljs-number">50%</span><br>      <span class="hljs-attribute">background</span>: <span class="hljs-number">#fc625d</span><br>      <span class="hljs-attribute">box-shadow</span>: <span class="hljs-number">20px</span> <span class="hljs-number">0</span> <span class="hljs-number">#fdbc40</span>, <span class="hljs-number">40px</span> <span class="hljs-number">0</span> <span class="hljs-number">#35cd4b</span><br></code></pre></td></tr></table></figure><ol start="3"><li><strong>注入配置：</strong> 在 <code>_config.fluid.yml</code> 中注册：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">custom_css:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">/css/mac.css</span><br></code></pre></td></tr></table></figure><p><em>注意：虽然源文件是 stylus，Hexo 会自动编译为 css，此处引用需写 .css 后缀。</em></p><h2 id="数学公式渲染-LaTeX"><a href="#数学公式渲染-LaTeX" class="headerlink" title="数学公式渲染 (LaTeX)"></a>数学公式渲染 (LaTeX)</h2><p>为了在技术文章中优雅地展示公式，使用 <code>hexo-math</code>。 </p><p>安装<code>hexo-math</code>插件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 使用 npm 安装 Hexo-math插件</span><br><span class="hljs-comment">## Docs: https://github.com/hexojs/hexo-math</span><br>npm install hexo-math --save<br></code></pre></td></tr></table></figure><p>在站点 <code>_config.yml</code> 中添加：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Hexo-math</span><br><span class="hljs-comment">## Docs: https://github.com/hexojs/hexo-math</span><br><span class="hljs-attr">math:</span><br>  <span class="hljs-attr">katex:</span><br>    <span class="hljs-attr">css:</span> <span class="hljs-string">&#x27;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css&#x27;</span><br>    <span class="hljs-attr">options:</span><br>      <span class="hljs-attr">throwOnError:</span> <span class="hljs-literal">false</span><br>  <span class="hljs-attr">mathjax:</span><br>    <span class="hljs-attr">css:</span> <span class="hljs-string">&#x27;https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css&#x27;</span><br>    <span class="hljs-attr">options:</span><br>      <span class="hljs-attr">conversion:</span><br>        <span class="hljs-attr">display:</span> <span class="hljs-literal">false</span><br>      <span class="hljs-attr">tex:</span><br>      <span class="hljs-attr">svg:</span><br></code></pre></td></tr></table></figure><p><em>优化建议：默认对所有页面关闭公式渲染（提升加载速度），仅在需要的文章 Front-matter 中开启(参见后文 Front-matter 部分)</em></p><h1 id="5-内容生产流"><a href="#5-内容生产流" class="headerlink" title="5. 内容生产流"></a>5. 内容生产流</h1><h2 id="Front-matter-模板工程化"><a href="#Front-matter-模板工程化" class="headerlink" title="Front-matter 模板工程化"></a>Front-matter 模板工程化</h2><p>修改 <code>scaffolds/post.md</code>，预设常用的元数据，减少重复劳动：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> &#123;&#123; <span class="hljs-string">title</span> &#125;&#125;<br><span class="hljs-attr">date:</span> &#123;&#123; <span class="hljs-string">date</span> &#125;&#125;<br><span class="hljs-attr">updated:</span><br><span class="hljs-attr">index_img:</span><br><span class="hljs-attr">category_bar:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">categories:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">Foo</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">Bar</span><br><span class="hljs-attr">tags:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">Foo</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">Bar</span><br><span class="hljs-attr">katex:</span> <span class="hljs-literal">false</span><br><span class="hljs-attr">mathjax:</span> <span class="hljs-literal">false</span><br><span class="hljs-attr">excerpt:</span> <span class="hljs-string">&#x27;&#x27;</span><br><span class="hljs-attr">sticky:</span> <br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br></code></pre></td></tr></table></figure><h2 id="静态资源压缩"><a href="#静态资源压缩" class="headerlink" title="静态资源压缩"></a>静态资源压缩</h2><p>在构建流水线中加入压缩环节，减少传输体积。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 使用 npm 安装 hexo-all-minifier 插件</span><br><span class="hljs-comment">## Docs: https://github.com/chenzhutian/hexo-all-minifier</span><br>npm install hexo-all-minifier --save<br></code></pre></td></tr></table></figure><p>在 <code>_config.yml</code> 开启:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># All in one. Minifier &amp; Optimization plugin for Hexo.</span><br><span class="hljs-comment">## Docs: https://github.com/chenzhutian/hexo-all-minifier</span><br><span class="hljs-attr">all_minifier:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><h1 id="6-高可用部署架构"><a href="#6-高可用部署架构" class="headerlink" title="6. 高可用部署架构"></a>6. 高可用部署架构</h1><p>本站采用 <strong>双线热备</strong> 方案。GitHub 仅作为代码仓库，由 Cloudflare Pages 和 Vercel 负责分发。</p><pre><code class=" mermaid">graph LR    User(用户访问) --&gt; DNS&#123;Cloudflare DNS&#125;    DNS -- &quot;线路优选 (默认)&quot; --&gt; CF[Cloudflare Pages]    DNS -- &quot;故障切换 (备用)&quot; --&gt; Vercel[Vercel]    CF -- &quot;自动拉取&quot; --&gt; GH[(GitHub Repo)]    Vercel -- &quot;自动拉取&quot; --&gt; GH</code></pre><h2 id="6-1-部署到-GitHub-Pages-基础"><a href="#6-1-部署到-GitHub-Pages-基础" class="headerlink" title="6.1 部署到 GitHub Pages (基础)"></a>6.1 部署到 GitHub Pages (基础)</h2><p>这是最经典的部署方式，通过 Git 钩子将生成的静态文件推送到 GitHub 仓库。哪怕后续使用 CDN 加速，保留原始的 GitHub Pages 也是极好的“源站”备份。</p><ol><li><strong>创建仓库：</strong> 在 GitHub 上创建一个名为 <code>tianyuxbear.github.io</code> 的公开仓库。</li><li><strong>安装部署插件：</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 使用 npm 安装 Github Deploy插件</span><br>npm install hexo-deployer-git --save<br></code></pre></td></tr></table></figure><ol start="3"><li><strong>配置站点文件：</strong> 修改 <code>_config.yml</code> 中的部署模块：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Deployment</span><br><span class="hljs-comment">## Docs: https://hexo.io/docs/one-command-deployment</span><br><span class="hljs-attr">deploy:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attr">repo:</span> <span class="hljs-string">git@github.com:tianyuxbear/tianyuxbear.github.io.git</span><br>  <span class="hljs-attr">branch:</span> <span class="hljs-string">master</span><br></code></pre></td></tr></table></figure><ol start="4"><li><strong>一键部署</strong>： 执行以下组合命令，完成清除缓存、生成静态文件、推送部署：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d<br></code></pre></td></tr></table></figure><h2 id="6-2-部署至-Cloudflare-Pages-核心"><a href="#6-2-部署至-Cloudflare-Pages-核心" class="headerlink" title="6.2 部署至 Cloudflare Pages (核心)"></a>6.2 部署至 Cloudflare Pages (核心)</h2><p>相比 GitHub Pages，Cloudflare 提供国内更友好的 CDN 节点和 HTTP&#x2F;3 支持。</p><ol><li><strong>绑定仓库：</strong> 在 Cloudflare Dashboard 中关联 GitHub 账号，选择 <code>hexo-blog</code> 仓库。</li><li><strong>构建配置：</strong><ul><li>Build Command: 空</li><li>Build Output Directory: 空(默认是&#x2F;)</li></ul></li><li><strong>等待部署：</strong> 点击部署，几分钟后即可通过 <a href="https://tianyuxbear-github-io.pages.dev/">https://tianyuxbear-github-io.pages.dev/</a> 访问。</li></ol><h2 id="6-3-部署至-Vercel-灾备"><a href="#6-3-部署至-Vercel-灾备" class="headerlink" title="6.3 部署至 Vercel (灾备)"></a>6.3 部署至 Vercel (灾备)</h2><p>配置逻辑同上。Vercel 的国内访问速度在部分地区可能优于 Cloudflare，可作为互补。</p><ul><li><strong>Framework Preset:</strong> <code>Other</code>。</li><li><strong>Output Directory:</strong> <code>/</code>。</li></ul><p>部署成功后，即可通过 <a href="https://tianyuxbear-github-io.vercel.app/">https://tianyuxbear-github-io.vercel.app/</a> 访问。</p><h2 id="6-4-自定义域名配置-重要"><a href="#6-4-自定义域名配置-重要" class="headerlink" title="6.4 自定义域名配置 (重要)"></a>6.4 自定义域名配置 (重要)</h2><p>为了获得最佳的访问速度和 HTTPS 支持，我们采用 <strong>DNS 托管模式</strong> 将域名完全接入 Cloudflare。</p><p><strong>第一步：域名注册 (以阿里云为例)</strong></p><ol><li>在阿里云官网购买域名（如 <code>codebearjourney.top</code>）。</li><li>完成实名认证。</li></ol><p><strong>第二步：DNS 迁移至 Cloudflare</strong> 这是加速的关键步骤。将域名的 DNS 解析权交给 Cloudflare，利用其全球 Anycast 网络。</p><ol><li>登录 Cloudflare Dashboard，点击 “Add a Site”，输入你的域名。</li><li>选择 “Free” 计划。</li><li>Cloudflare 会扫描当前的 DNS 记录，确认无误后点击 Continue。</li><li><strong>修改 Nameservers：</strong><ul><li>Cloudflare 会提供两个 Nameserver 地址（如 <code>bob.ns.cloudflare.com</code> 等）。</li><li>回到阿里云域名控制台 -&gt; 域名列表 -&gt; 管理 -&gt; DNS 修改 -&gt; 修改 DNS 服务器。</li><li>将阿里云默认的 DNS 修改为 Cloudflare 提供的这两个地址。</li></ul></li><li>等待生效（通常在 10 分钟到 24 小时内）。</li></ol><p><strong>第三步：绑定 Pages</strong></p><ol><li>在 Cloudflare Pages 项目页面，点击 “Custom domains”。</li><li>输入 <code>codebearjourney.top</code>。</li><li>由于你的 DNS 已经托管在 Cloudflare，系统会自动添加 CNAME 记录并申请 SSL 证书。</li><li>(可选) 同时添加 <code>www.codebearjourney.top</code> 并设置重定向，符合用户习惯。</li></ol><p>通过此配置，访问请求路径为： <code>用户</code> -&gt; <code>Cloudflare 边缘节点 (DNS+CDN)</code> -&gt; <code>Pages 静态资源</code>。</p><h1 id="7-SEO-与收录优化"><a href="#7-SEO-与收录优化" class="headerlink" title="7. SEO 与收录优化"></a>7. SEO 与收录优化</h1><p>为了让 Google 和 Bing 快速索引，我们需要配置 Sitemap 并完成站长验证。</p><h2 id="7-1-生成-Sitemap"><a href="#7-1-生成-Sitemap" class="headerlink" title="7.1 生成 Sitemap"></a>7.1 生成 Sitemap</h2><p>告诉搜索引擎你的网站结构和文章路径。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 使用 npm 安装 Hexo-sitemap 插件</span><br>npm install hexo-generator-sitemap --save<br></code></pre></td></tr></table></figure><p>在 <code>_config.yml</code> 确认开启：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># 确保 sitemap 插件已启用</span><br><span class="hljs-attr">sitemap:</span><br>  <span class="hljs-attr">path:</span> <span class="hljs-string">sitemap.xml</span><br></code></pre></td></tr></table></figure><h2 id="7-2-站长平台验证-DNS-方式"><a href="#7-2-站长平台验证-DNS-方式" class="headerlink" title="7.2 站长平台验证 (DNS 方式)"></a>7.2 站长平台验证 (DNS 方式)</h2><p>传统的验证方式是上传一个 HTML 文件到 <code>public 目录</code>，这会污染源码且容易在重构中丢失。<strong>强烈推荐使用 Cloudflare DNS 进行 TXT 记录验证</strong>，这种方式无代码侵入，且得益于 Cloudflare 的生效速度，通常秒级通过。</p><p><strong>Google Search Console</strong></p><ol><li><strong>获取验证码：</strong><ul><li>登录 <a href="https://search.google.com/search-console">Google Search Console</a>。</li><li>在左上角选择资源类型时，选择 <strong>“网域” (Domain)</strong>（而不是 “网址前缀”）。</li><li>输入你的域名（不带 https，如 <code>codebearjourney.top</code>）。</li><li>系统会弹出一个对话框，复制显示的 <strong>TXT 记录值</strong>（通常以 <code>google-site-verification=</code> 开头）。</li></ul></li><li><strong>Cloudflare 配置：</strong><ul><li><p>登录 Cloudflare Dashboard，进入你的域名页面。</p></li><li><p>点击左侧菜单 <strong>DNS -&gt; Records</strong>。</p></li><li><p>点击 <strong>Add record</strong> 按钮：</p><ul><li><strong>Type:</strong> 选择 <code>TXT</code></li><li><strong>Name:</strong> 输入 <code>@</code> (代表根域名)</li><li><strong>Content:</strong> 粘贴刚才复制的 <code>google-site-verification=...</code> 字符串</li><li><strong>TTL:</strong> 保持 <code>Auto</code></li></ul></li><li><p>点击 <strong>Save</strong>。</p></li></ul></li><li><strong>完成验证：</strong><ul><li>回到 Google Search Console 页面，点击 <strong>验证</strong> 按钮。通常会立即提示“已验证所有权”。</li></ul></li></ol><p><strong>Bing Webmaster Tools</strong><br>微软提供了一个极其高效的“偷懒”路径：</p><ol><li>登录 <a href="https://www.bing.com/webmasters/about">Bing Webmaster Tools</a>。</li><li>选择 “<strong>Import from Google Search Console</strong>“（从 GSC 导入）。</li><li>授权你的 Google 账号，Bing 会自动同步你的站点验证状态和 Sitemap 地址，无需再手动添加 DNS 记录。</li></ol><h2 id="7-3-提交-Sitemap"><a href="#7-3-提交-Sitemap" class="headerlink" title="7.3 提交 Sitemap"></a>7.3 提交 Sitemap</h2><p>验证通过后，别忘了最后一步：</p><ol><li>确认 <code>https://codebearjourney.top/sitemap.xml</code> 可以访问。</li><li>在 Google&#x2F;Bing 后台的 <strong>Sitemaps</strong> 菜单中，填入 <code>sitemap.xml</code> 并提交。</li></ol><h1 id="8-多端同步工作流"><a href="#8-多端同步工作流" class="headerlink" title="8. 多端同步工作流"></a>8. 多端同步工作流</h1><p>由于采用了 Submodule 和标准化的 npm 依赖管理，在新设备上恢复工作流极其简单：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 1. 克隆主仓库</span><br>git <span class="hljs-built_in">clone</span> git@github.com:tianyuxbear/hexo-blog.git<br><span class="hljs-built_in">cd</span> hexo-blog<br><br><span class="hljs-comment"># 2. 递归恢复子模块 (还原 fluid 主题)</span><br>git submodule update --init --recursive<br><br><span class="hljs-comment"># 3. 恢复插件依赖 (根据 package.json)</span><br>npm install<br></code></pre></td></tr></table></figure><p>至此，环境完全复刻，可以开始写作了。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://hexo.io/zh-cn/docs/">Hexo官方文档</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a href="https://hexo.fluid-dev.com/docs/">Hexo Fluid 用户手册</a><a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a href="https://hewei2001.pages.dev/Hello-My-World">Hello My World</a><a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a href="https://hewei2001.pages.dev/Hexo-Configuration#%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE">Hexo配置与扩展</a><a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>配置指南</category>
      
      <category>博客搭建</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Fluid</tag>
      
      <tag>CI/CD</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
